\chapterimage{nonlinear-control.jpg}{Trees by Interdisciplinary Sciences building at UCSC}

\chapter{Nonlinear control}
\label{ch:nonlinear_control}

While many tools exist for designing controllers for linear \glspl{system}, all
\glspl{system} in reality are inherently nonlinear. We'll briefly mention some
considerations for nonlinear \glspl{system}.

\section{Introduction}

Recall from linear \gls{system} theory that we defined \glspl{system} as having
the following form:

\begin{align*}
  \dot{\mtx{x}} &= \mtx{A}\mtx{x} + \mtx{B}\mtx{u} + \mtx{\Gamma}\mtx{w} \\
  \mtx{y} &= \mtx{C}\mtx{x} + \mtx{D}\mtx{u} + \mtx{v}
\end{align*}

In this equation, $\mtx{A}$ and $\mtx{B}$ are constant matrices. In nonlinear
\glspl{system}, the \gls{state} evolution and \gls{output} are defined by
arbitrary functions of the current \glspl{state} and \glspl{input}.

\begin{align*}
  \dot{\mtx{x}} &= f(\mtx{x}, \mtx{u}, \mtx{w}) \\
  \mtx{y} &= h(\mtx{x}, \mtx{u}, \mtx{v})
\end{align*}

\section{Linearization}
\index{Nonlinear control!linearization}

One way to control nonlinear \glspl{system} is to
\glslink{linearization}{linearize} the \gls{model} around a reference point.
Then, all the powerful tools that exist for linear controls can be applied. This
is done by taking the partial derivative of the functions.

\begin{align*}
  \begin{array}{cccc}
    \mtx{A} = \frac{\partial f(\mtx{x}, \mtx{0}, \mtx{0})}{\partial \mtx{x}} &
    \mtx{B} = \frac{\partial f(\mtx{0}, \mtx{u}, \mtx{0})}{\partial \mtx{u}} &
    \mtx{C} = \frac{\partial h(\mtx{x}, \mtx{0}, \mtx{0})}{\partial \mtx{x}} &
    \mtx{D} = \frac{\partial h(\mtx{0}, \mtx{u}, \mtx{0})}{\partial \mtx{u}}
  \end{array}
\end{align*}

Higher order partial derivatives can be added to better approximate the
nonlinear dynamics. We typically only \glslink{linearization}{linearize} around
equilibrium points because we are interested in how the \gls{system} behaves
when perturbed from equilibrium. An FAQ on this goes into more detail
\cite{bib:linearize_equilibrium_point}. To be clear though,
\glslink{linearization}{linearizing} the \gls{system} around the current
\gls{state} as the \gls{system} evolves does give a closer approximation over
time.

\section{Nonlinear observers}

In this book, we have covered the Kalman filter, which is the optimal unbiased
estimator for linear \glspl{system}. It isn't optimal for nonlinear
\glspl{system}, but several extensions to it have been developed to make it more
accurate.

\subsection{Extended Kalman filter}
\index{Nonlinear control!extended Kalman filter}
\index{State-space observers!Kalman filter!extended Kalman filter}

This method \glslink{linearization}{linearizes} the matrices used during the
prediction step. In addition to the $\mtx{A}$, $\mtx{B}$, $\mtx{C}$, and
$\mtx{D}$ matrices above, the process noise intensity vector $\Gamma$ is
\glslink{linearization}{linearized} as follows:

\begin{equation*}
  \mtx{\Gamma} = \frac{\partial f(\mtx{x}, \mtx{0}, \mtx{0})}{\partial \mtx{w}}
\end{equation*}

where $\mtx{w}$ is the process noise included in the stochastic model.

From there, the continuous Kalman filter equations are used like normal to
compute the error covariance matrix $\mtx{P}$ and Kalman gain matrix. The
\gls{state} estimate update can still use the function $h(\mtx{x})$ for
accuracy.

\begin{equation*}
  \hat{\mtx{x}}_{k+1}^+ = \hat{\mtx{x}}_{k+1}^- +
    \mtx{K}_{k+1}(\mtx{y}_{k+1} - h(\hat{\mtx{x}}_{k+1}^-))
\end{equation*}

\subsection{Unscented Kalman filter}
\index{Nonlinear control!unscented Kalman filter}
\index{State-space observers!Kalman filter!unscented Kalman filter}

This method \glslink{linearization}{linearizes} around carefully chosen points
to minimize the modeling error. There's a lot of detail to cover, so we
recommend just reading a paper on it \cite{bib:unscented_kalman_filter}.

Here's a paper on a quaternion-based Unscented Kalman filter for orientation
tracking \cite{bib:ukf_state_tracking}.

\section{Lyapunov stability}
\index{Nonlinear control!Lyapunov stability}

Lyapunov stability is a fundamental concept in nonlinear control, so we're going
to give a brief overview of what it is so students can research it further.

Since the \gls{state} evolution in nonlinear \glspl{system} is defined by a
function rather than a constant matrix, the \gls{system}'s poles as determined
by \gls{linearization} move around. Nonlinear control uses Lyapunov stability to
determine if nonlinear \glspl{system} are stable. From a linear control theory
point of view, Lyapunov stability says the \gls{system} is stable if, for a
given initial condition, all possible eigenvalues of $\mtx{A}$ from that point
on remain in the left-half plane. However, nonlinear control uses a different
definition.

Essentially, Lyapunov stability means that the \gls{system} trajectory can be
kept arbitrarily close to the origin by starting sufficiently close to it.
Lyapunov's direct method is concerned with finding a function representing the
energy in a \gls{system} to prove that the \gls{system} is stable around an
equilibrium point. This can be used to prove a \gls{system}'s open-loop
stability as well as its closed-loop stability in the presence of a controller.
Typically, these functions include the energy of the \gls{system} or the
derivatives of the \gls{system} \gls{state}, which are then used to show the
\gls{system} decays to some ground state.

Lyapunov functions are merely sufficient to prove stability (as opposed to a
specific Lyapunov function being necessary). If one function doesn't prove it,
another candidate should be tried. For this reason, we refer to these functions
as \textit{Lyapunov candidate functions}.

\section{Nonlinear control law for unicycle}

The paper \textit{Control of Wheeled Mobile Robots: An Experimental Overview}
describes a nonlinear controller for a wheeled vehicle with unicycle-like
kinematics and a global \gls{pose} consisting of $x$, $y$, and $\theta$
\cite{bib:ctrl_wheeled_mobile_robots}. They use the following Lyapunov function.

\begin{equation*}
  V = \frac{\overline{k}_2}{2}(e_1^2 + e_2^2) + \frac{e_3^2}{2}
\end{equation*}

where $\overline{k}_2$ is a tuning constant, $e_1$ is the tracking error in $x$,
$e_2$ is the tracking error in $y$, and $e_3$ is the tracking error in $\theta$.

The time derivative along the solutions of the closed-loop \gls{system} is
nonincreasing since

\begin{equation*}
  \dot{V} = -k_1 \overline{k}_2 e_1^2 - k_3 e_3^2 \leq 0
\end{equation*}

Thus, $\lVert e(t) \rVert$ is bounded, $\dot{V}(t)$ is uniformly continuous,
and $V(t)$ tends to some limit value. Using the Barbalat lemma, $\dot{V}(t)$
tends to zero \cite{bib:ctrl_wheeled_mobile_robots}.

The commanded velocity $v$ and turning rate $\omega$ are

\begin{align}
  v =~& v_d \cos(\theta_d - \theta) + k_1(v_d, \omega_d)(\cos\theta(x_d - x) +
    \sin\theta(y_d - y)) \\
  \omega =~& \omega_d +
    \overline{k}_2 v_d\frac{\sin(\theta_d - \theta)}{\theta_d - \theta}
    (\cos\theta(x_d - x) - \sin\theta(y_d - y)) + \nonumber \\
    &k_3 (v_d, \omega_d)(\theta_d - \theta) \\
  k_1(v_d(t), \omega_d(t)) =~& k_3(v_d(t), \omega_d(t)) =
    2\zeta\sqrt{\omega_d^2(t) + bv_d^2(t)}
\end{align}

where $v_d$ is the desired velocity, $x_d$ is the desired $x$ position, $y_d$ is
the desired $y$ position, and $\overline{k}_2 = b$ with $b > 0$ and
$\zeta \in (0, 1)$.

$v$ and $\omega$ should be the \glspl{reference} for a \gls{reference} tracker
for the drivetrain. This can be a linear controller.

$x$, $y$, and $\theta$ are obtained via a nonlinear \gls{pose} estimator. The
simplest way to do this is by integrating the velocity in each orthogonal
direction over time using

\begin{align*}
  x_{k+1} = x_k + v_k\cos\theta_k\,T \\
  y_{k+1} = y_k + v_k\sin\theta_k\,T
\end{align*}

where $T$ is the sample period. $x_d$, $y_d$, and $\theta_d$ are obtained from a
desired time-based trajectory.

\subsection{Two-wheeled vehicle}

The mapping from $v$ and $\omega$ to the left and right wheel velocities $v_L$
and $v_R$ are derived as follows.

\begin{align}
  v &= \frac{v_R + v_L}{2} \label{eq:ramsete_v} \\
  \omega &= \frac{v_R - v_L}{d} \label{eq:ramsete_w}
\end{align}

where $d$ is the trackwidth.

\begin{align*}
  \omega d &= v_R - v_L \\
  \omega d + v_L &= v_R
\end{align*}

Substitute this into equation (\ref{eq:ramsete_v}) and solve for $v_L$.

\begin{align}
  v &= \frac{(\omega d + v_L) + v_L}{2} \nonumber \\
  v &= \frac{\omega d + 2v_L}{2} \nonumber \\
  2v &= \omega d + 2v_L \nonumber \\
  2v - \omega d &= 2v_L \nonumber \\
  v_L &= v - \frac{\omega d}{2}
\end{align}

Substitute this back into equation (\ref{eq:ramsete_v}) and solve for $v_R$.

\begin{align}
  v &= \frac{v_R + (v - \frac{\omega d}{2})}{2} \nonumber \\
  2v &= v_R + v - \frac{\omega d}{2} \nonumber \\
  v &= v_R - \frac{\omega d}{2} \nonumber \\
  v_R &= v + \frac{\omega d}{2}
\end{align}

\section{Further reading}

For learning more about nonlinear control, we recommend reading the book
\textit{Applied Nonlinear Control} by Jean-Jacques Slotine. For a more complex
type of nonlinear control, read \textit{A guiding vector field algorithm for
path following control of nonholonomic mobile robots} \cite{bib:gvf}.
