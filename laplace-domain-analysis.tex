\chapterimage{laplace-domain-analysis.jpg}{Grass clearing by Interdisciplinary Sciences building and Thimann Labs at UCSC}

\chapter{Laplace domain analysis}

\section{Locations of poles and zeroes}

The locations of the closed-loop poles in the complex plane determine the
stability of the \gls{system}. Each pole represents a frequency mode of the
\gls{system}, and their location determines how much of each response is induced
for a given input frequency. Figure \ref{fig:system_response_poles} shows the
time domain responses for transfer functions with various pole locations. They
all have an initial condition of one.

\begin{bookfigure}
  \begin{tikzpicture}[auto, >=latex']
    % \draw [help lines] (-4,-2) grid (4,4);

    % Draw main axes
    \draw[->] (-4.2,0) -- (4.2,0) node[below] {\small Re($\sigma$)};
    \draw[->] (0,-2) -- (0,4.2) node[right] {\small Im($j\omega$)};

    % Stable: e^-1.75t * cos(1.75wt) (80/3*w for readability)
    \drawtimeplot{-2.125cm}{2.5cm}{0.125cm}{0.44375cm}{
      exp(-1.75 * \x) * cos(80/3 * 1.75 * deg(\x))}
    \drawpole{-1.75cm}{1.75cm}

    % Stable: e^-2.5t
    \drawtimeplot{-2.25cm}{0.75cm}{0.125cm}{0.125cm}{exp(-2 * \x)}
    \drawpole{-2cm}{0cm}

    % Stable: e^-t
    \drawtimeplot{-1.125cm}{-0.75cm}{0.125cm}{0.125cm}{exp(-\x)}
    \drawpole{-1cm}{0cm}

    % Marginally stable: cos(wt) (80/3*w for readability)
    \drawtimeplot{-0.75cm}{1.125cm}{0.125cm}{0.44375cm}{cos(80/3 * deg(\x))}
    \drawpole{0cm}{1cm}

    % Marginally stable cos(2wt) (80/3*w for readability)
    \drawtimeplot{0cm}{2.75cm}{0.125cm}{0.44375cm}{cos(80/3 * 2 * deg(\x))}
    \drawpole{0cm}{2cm}

    % Integrator
    \drawtimeplot{0.25cm}{-0.75cm}{0.125cm}{0.125cm}{1}
    \drawpole{0cm}{0cm}

    % Unstable: e^t
    \drawtimeplot{1.125cm}{0.75cm}{0.125cm}{0.125cm}{exp(\x)}
    \drawpole{1cm}{0cm}

    % Unstable: e^2t
    \drawtimeplot{2.25cm}{-0.75cm}{0.125cm}{0.125cm}{exp(2 * \x)}
    \drawpole{2cm}{0cm}

    % Unstable: e^0.75t * cos(1.75wt) (80/3*w for readability)
    \drawtimeplot{1.5cm}{2.25cm}{0.125cm}{0.44375cm}{
      exp(0.75 * \x) * cos(80/3 * 1.75 * deg(\x))}
    \drawpole{0.75cm}{1.75cm}

    % LHP and RHP labels
    \draw (-3.5,1.5) node {LHP};
    \draw (3.5,1.5) node {RHP};

    % Stable and unstable labels
    \draw (-2.5,3.5) node {\small Stable};
    \draw (2.5,3.5) node {\small Unstable};
  \end{tikzpicture}

  \caption{Time domain system response vs pole location}
  \label{fig:system_response_poles}
\end{bookfigure}

\begin{booktable}
  \begin{tabular}{|ll|}
    \hline
    \rowcolor{headingbg}
    \textbf{Location} & \textbf{Stability} \\
    \hline
    Left Half-plane (LHP) & Stable \\
    Imaginary axis & Marginally stable \\
    Right Half-plane (RHP) & Unstable \\
    \hline
  \end{tabular}

  \caption{Pole location and stability}
  \label{tab:pole_locations}
\end{booktable}

When a system is stable, its output may oscillate but it converges to
steady-state. When a system is marginally stable, its output oscillates at a
constant amplitude forever. When a system is unstable, its output grows without
bound.

\section{Root locus}

In closed-loop, the poles and zeroes can be moved around by adjusting the
controller gain. The root locus shows where they will go as the controller gain is
increased. Figure \ref{fig:poster_rlocus} shows the root locus of the transfer
function from equation (\ref{eq:transfer_func}).

\begin{svg}{root_locus}
  \caption{Root locus of equation (\ref{eq:transfer_func}). See snippet
    \ref{lst:poster_rlocus}.}
  \label{fig:poster_rlocus}
\end{svg}

\begin{snippet}
  \caption{Root locus in Python}
  \label{lst:poster_rlocus}
  \includecode[Python]{code/root_locus.py}
\end{snippet}

As the controller gain increases, the poles move toward the zeroes. In this
case, the \gls{system} eventually becomes unstable.

\begin{remark}
  If poles are much farther left in the LHP than the typical \gls{system}
  dynamics exhibit, they can be considered negligible. Every \gls{system} has
  some form of unmodeled high frequency, nonlinear dynamics, but they can be
  safely ignored depending on the operating regime.
\end{remark}

\subsection{Non-minimum phase zeroes}

While poles in the RHP are unstable, the same is not true for zeroes. They can
be characterized by the \gls{system} initially moving in the wrong direction
before heading toward the \gls{reference}. Since the poles always move toward
the zeroes, zeroes impose a ``speed limit" on the \gls{system} response because
it takes a finite amount of time to move the wrong direction, then change
directions.

One example of this type of system is bicycle steering. Try riding a bicycle
without holding the handle bars, then poke the right handle; the bicycle turns
right. Conversely, if one is holding the handlebars and wants to turn left,
rotating the handlebars counterclockwise will make the bicycle fall toward the
right. The rider has to lean into the turn and overpower the non-minimum phase
dymamics to go the desired direction.

Another example is a segway. To move forward by some distance, the segway must
first roll backward to rotate the segway forward. Once the segway starts falling
in that direction, it begins rolling forward to avoid falling over until
it reaches the target distance. At that point, the segway increases its forward
speed to pitch backward and slow itself down. To come to a stop, the segway
rolls backward again to level itself out.

\section{Gain margin and phase margin} \label{sec:gain-phase-margin}

One generally needs to learn about Bode plots and Nyquist plots to truly
understand gain and phase margin and their origins, but those plots are large
topics unto themselves. Since we won't be using either of these plots for
controller design, we'll just cover what gain and phase margin are in a general
sense and how they are used.

Gain margin and phase margin are two metrics for measuring a system's relative
stability. Gain and phase margin are the amounts by which the closed-loop gain
and phase can be varied respectively before the system becomes unstable. In a
sense, they are safety margins for when unmodeled dynamics affect the system
response.

For a more thorough explanation of gain and phase margin, watch Brian Douglas's
video on them \cite{bib:gain_phase_margin}. He has other videos too on classical
control methods like Bode and Nyquist plots that we recommend.

\section{Case studies}

\subsection{Flywheel PID control}

PID controllers typically control voltage to a motor in FRC independent of the
equations of motion of that motor. For position PID control, large values of
$K_p$ can lead to overshoot and $K_d$ is commonly used to reduce overshoots.
Let's consider a flywheel controlled with a standard PID controller. Why
wouldn't $K_d$ provide damping for velocity overshoots in this case?

PID is designed to control second order and first order systems well. It can be
used to control a lot of things, but struggles when given higher order systems.
It has three degrees of freedom. Two are used to place the two poles of the
system, and the third is used to remove steady state error. With higher order
systems like a one input, seven state system, there aren't enough degrees of
freedom to place the system's poles in desired locations. This will result in
poor control.

The math for PID doesn't assume voltage, a motor, etc. It defines an output
based on derivatives and integrals of the input. We happen to use it for motors
because it actually works pretty well for it because motors are second order
systems.

The following math will be in continuous time, but the same ideas apply to
discrete time. This is all assuming a velocity controller.

Our simple motor model hooked up to a mass is

\begin{align}
  V &= IR + \frac{\omega}{K_v} \label{eq:cs_flywheel_1} \\
  \tau &= I K_t \label{eq:cs_flywheel_2} \\
  \tau &= J \frac{d\omega}{dt} \label{eq:cs_flywheel_3}
\end{align}

First, we'll solve for $\frac{d\omega}{dt}$ in terms of $V$.

Substitute equation (\ref{eq:cs_flywheel_2}) into equation
 (\ref{eq:cs_flywheel_1}).

\begin{align*}
  V &= IR + \frac{\omega}{K_v} \\
  V &= \left(\frac{\tau}{K_t}\right) R + \frac{\omega}{K_v}
\end{align*}

Substitute in equation (\ref{eq:cs_flywheel_3}).

\begin{align*}
  V &= \frac{\left(J \frac{d\omega}{dt}\right)}{K_t} R + \frac{\omega}{K_v} \\
\end{align*}

Solve for $\frac{d\omega}{dt}$.

\begin{align*}
  V &= \frac{J \frac{d\omega}{dt}}{K_t} R + \frac{\omega}{K_v} \\
  V - \frac{\omega}{K_v} &= \frac{J \frac{d\omega}{dt}}{K_t} R \\
  \frac{d\omega}{dt} &= \frac{K_t}{JR} \left(V - \frac{\omega}{K_v}\right) \\
  \frac{d\omega}{dt} &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V
\end{align*}

Now take the Laplace transform.

\begin{equation}
  s \omega = -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V
  \label{eq:cs_motor_tf}
\end{equation}

Solve for the transfer function $H(s) = \frac{\omega}{V}$.

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V \\
  \left(s + \frac{K_t}{JRK_v}\right) \omega &= \frac{K_t}{JR} V \\
  \frac{\omega}{V} &= \frac{\frac{K_t}{JR}}{s + \frac{K_t}{JRK_v}} \\
\end{align*}

That gives us a pole at $-\frac{K_t}{JRK_v}$, which is actually stable. Notice
that there is only one pole.

First, we'll use a simple P loop (going to drive it to 0 without loss of
generality).

\begin{equation*}
  V = K_p (\omega_{goal} - \omega)
\end{equation*}

Substitute this controller into equation (\ref{eq:cs_motor_tf}).

\begin{equation*}
  s \omega = -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} K_p (\omega_{goal} -
    \omega)
\end{equation*}

Solve for the transfer function $H(s) = \frac{\omega}{\omega_{goal}}$.

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} (\omega_{goal} -
    \omega) \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} \omega_{goal} -
    \frac{K_t K_p}{JR} \omega \\
  \left(s + \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right) \omega &=
    \frac{K_t K_p}{JR} \omega_{goal} \\
  \frac{\omega}{\omega_{goal}} &= \frac{\frac{K_t K_p}{JR}}
    {\left(s + \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)} \\
\end{align*}

This has a pole at $-\left(\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)$.
Assuming that that quantity is negative (i.e., we are stable), that pole
corresponds to a time constant of
$\frac{1}{\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}}$.

As can be seen above, a flywheel has a single pole. It therefore only needs a
single pole controller to place all of its poles anywhere.

\begin{remark}
  This analysis assumes that the motor is well coupled to the mass and that the
  time constant of the inductor is fast enough that it doesn't factor into the
  motor equations. In Austin Schuh's experience with 971's robots, these are
  pretty good assumptions.
\end{remark}

Next, we'll try a PD loop. (This will use a perfect derivative, but anyone
following along closely already knows that we can't really take a derivative
here, so the math will need to be updated at some point. We could switch to
discrete time and pick a differentiation method, or pick some other way of
modeling the derivative.)

\begin{equation*}
  V = K_p (\omega_{goal} - \omega) + K_d s (\omega_{goal} - \omega)
\end{equation*}

Substitute this controller into equation (\ref{eq:cs_motor_tf}).

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR}
    \left(K_p (\omega_{goal} - \omega) + K_d s (\omega_{goal} - \omega)\right)
    \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR}
    (\omega_{goal} - \omega) + \frac{K_t K_d s}{JR} (\omega_{goal} - \omega) \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} \omega_{goal} -
    \frac{K_t K_p}{JR} \omega + \frac{K_t K_d s}{JR} \omega_{goal} -
    \frac{K_t K_d s}{JR} \omega \\
\end{align*}

Collect the common terms on separate sides and refactor.

\begin{align*}
  s \omega + \frac{K_t K_d s}{JR} \omega + \frac{K_t}{JRK_v} \omega +
    \frac{K_t K_p}{JR} \omega &= \frac{K_t K_p}{JR} \omega_{goal} +
    \frac{K_t K_d s}{JR} \omega_{goal} \\
  \left(s \left(1 + \frac{K_t K_d}{JR}\right) + \frac{K_t}{JRK_v} +
    \frac{K_t K_p}{JR}\right) \omega &= \frac{K_t}{JR}
    \left(K_p + K_d s\right) \omega_{goal} \\
  \frac{\omega}{\omega_{goal}} &= \frac{\frac{K_t}{JR}
    \left(K_p + K_d s\right)}{\left(s \left(1 + \frac{K_t K_d}{JR}\right) +
    \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)} \\
\end{align*}

So, we added a zero at $-\frac{K_p}{K_d}$ and moved our pole to
$-\frac{\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}}{1 + \frac{K_t K_d}{JR}}$. This
isn't progress. We've added more complexity to our system and, practically
speaking, gotten nothing good out of it. Zeros should be avoided if at all
possible because they amplify unwanted high frequency modes of the system. At
least this is a stable zero, but still.

In summary, derivative doesn't help on a flywheel. $Kd$ may help if the real
system isn't ideal, but we don't suggest relying on that.

\subsection{Steady-state error}

To demonstrate the problem of \gls{steady-state error}, we will use a DC brushed
motor controlled by a velocity PID controller. A DC brushed motor has a transfer
function from voltage ($V$) to angular velocity ($\dot{\theta}$) of

\begin{equation}
  G(s) = \frac{\dot{\Theta}(s)}{V(s)} = \frac{K}{(Js+b)(Ls+R)+K^2}
\end{equation}

First, we'll try controlling it with a P controller defined as

\begin{equation*}
  K(s) = K_p
\end{equation*}

When these are in unity feedback, the transfer function from the input voltage
to the error is

\begin{align*}
  \frac{E(s)}{V(s)} &= \frac{1}{1 + K(s)G(s)} \\
  E(s) &= \frac{1}{1 + K(s)G(s)} V(s) \\
  E(s) &= \frac{1}{1 + (K_p) \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} V(s) \\
  E(s) &= \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}} V(s)
\end{align*}

The steady-state of a transfer function can be found via

\begin{equation}
  \lim_{s\to0} sH(s)
\end{equation}

\begin{align}
  e_{ss} &= \lim_{s\to0} sE(s) \nonumber \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}} V(s)
    \nonumber \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}}
    \frac{1}{s} \nonumber \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}}
    \nonumber \\
  e_{ss} &= \frac{1}{1 + \frac{K_p K}{(J(0)+b)(L(0)+R)+K^2}} \nonumber \\
  e_{ss} &= \frac{1}{1 + \frac{K_p K}{bR+K^2}} \label{eq:ss_nonzero}
\end{align}

Notice that the \gls{steady-state error} is nonzero. To fix this, an integrator
must be included in the controller.

\begin{equation*}
  K(s) = K_p + \frac{K_i}{s}
\end{equation*}

The same steady-state calculations are performed as before with the new
controller.

\begin{align*}
  \frac{E(s)}{V(s)} &= \frac{1}{1 + K(s)G(s)} \\
  E(s) &= \frac{1}{1 + K(s)G(s)} V(s) \\
  E(s) &= \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \left(\frac{1}{s}\right) \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \left(\frac{1}{s}\right) \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \frac{s}{s} \\
  e_{ss} &= \lim_{s\to0} \frac{s}{s + \left(K_p s + K_i\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \\
  e_{ss} &= \frac{0}{0 + (K_p (0) + K_i)
    \left(\frac{K}{(J(0)+b)(L(0)+R)+K^2}\right)} \\
  e_{ss} &= \frac{0}{K_i \frac{K}{bR+K^2}}
\end{align*}

The denominator is nonzero, so $e_{ss} = 0$. Therefore, an integrator is
required to eliminate \gls{steady-state error} in all cases for this
\gls{model}.

It should be noted that $e_{ss}$ in equation (\ref{eq:ss_nonzero}) approaches
zero for $K_p = \infty$. This is known as a bang-bang controller. In practice,
an infinite switching frequency cannot be achieved, but it may be close enough
for some performance specifications.
