\chapterimage{laplace-domain-analysis.jpg}{Grass clearing by Interdisciplinary Sciences building and Thimann Labs at UCSC}

\chapter{Laplace domain analysis}

This chapter briefly discusses what transfer functions are, how the locations of
poles and zeroes affects system response and stability, and how controllers
affect pole locations. The case studies cover various aspects of PID control
using the algebraic approach of transfer functions.

\section{What is a transfer function?}

The Laplace domain is a two-dimensional coordinate system whose coordinates are
represented by a complex number $s = \sigma + j\omega$. The real part $\sigma$
cooresponds to the x-axis and the imaginary part $j\omega$ cooresponds to the
y-axis.

A transfer function maps an input coordinate to an output coordinate in the
Laplace domain. These can be obtained by applying the Laplace transform to a
differential equation and rearranging the terms to obtain a ratio of the output
variable to the input variable. Equation (\ref{eq:transfer_func}) is an example
of a transfer function.

\begin{equation} \label{eq:transfer_func}
  H(s) = \frac{(s-9+9i)(s-9-9i)}{s(s+10)}
\end{equation}

The factors of the numerator and denominator of a transfer function are called
residues. The roots of residues in the numerator are called zeroes while the
roots of residues in the denominator are called poles. We call them zeroes
because they make the residue approach zero, which makes the transfer function
also approach zero. Likewise, poles are called such because they make the
residue approach zero, which makes the transfer function approach infinity. On a
3D graph, they look like the poles of a circus tent.

Imaginary poles and zeroes always come in complex conjugate pairs (e.g.,
$-2 + 3i$, $-2 - 3i$).

\section{Transfer functions in feedback}

For \glspl{controller} to \glslink{regulator}{regulate} a system or
\glslink{tracking}{track} a reference, they must be placed in positive or
negative feedback with the \gls{plant} (whether to use positive or negative
depends on the \gls{plant} in question).

\begin{bookfigure}
  \begin{tikzpicture}[auto, >=latex']
    % Place the blocks
    \node [name=input] {$X(s)$};
    \node [sum, right=of input] (sum) {};
    \node [block, right=of sum] (K) {$K$};
    \node [block, right=of K] (G) {$G$};
    \node [right=of G] (output) {$Y(s)$};
    \node [block, below=of $(K)!0.5!(G)$] (H) {$H$};

    % Connect the nodes
    \draw [arrow] (input) -- node[pos=0.85] {$+$} (sum);
    \draw [arrow] (sum) -- node {} (K);
    \draw [arrow] (K) -- node {} (G);
    \draw [arrow] (G) -- node[name=y] {} (output);
    \draw [arrow] (y) |- (H);
    \draw [arrow] (H) -| node[pos=0.97, right] {$-$} (sum);
  \end{tikzpicture}

  \caption{Feedback controller block diagram}
  \label{fig:feedback_controller_block_diagram}
\end{bookfigure}

\begin{figurekey}
  \begin{tabulary}{\linewidth}{LLLL}
    $X(s)$ & input & $H$ & measurement transfer function \\
    $K$ & controller gain & $Y(s)$ & output \\
    $G$ & plant transfer function & & \\
  \end{tabulary}
\end{figurekey}

The transfer function of figure \ref{fig:feedback_controller_block_diagram}, a
control system diagram with feedback, from input to output is

\begin{equation}
  G_{cl}(s) = \frac{Y(s)}{X(s)} = \frac{KG}{1 + KGH}
\end{equation}

The numerator is the \gls{open-loop gain} and the denominator is one plus the
gain around the feedback loop, which may include parts of the
\gls{open-loop gain} (see appendix \ref{ch:app-tf-feedback-deriv} for a
derivation). As another example, the transfer function from the input to the
error is

\begin{equation}
  G_{cl}(s) = \frac{E(s)}{X(s)} = \frac{1}{1 + KGH}
\end{equation}

The roots of the denominator of $G_{cl}(s)$ are different from those of the
open-loop transfer function $KG(s)$. These are called the closed-loop poles.

\section{Locations of poles and zeroes}
\index{Stability!poles and zeroes}

The locations of the closed-loop poles in the complex plane determine the
stability of the \gls{system}. Each pole represents a frequency mode of the
\gls{system}, and their location determines how much of each response is induced
for a given input frequency. Figure \ref{fig:system_response_poles} shows the
time domain responses for transfer functions with various pole locations. They
all have an initial condition of one.

\begin{bookfigure}
  \begin{tikzpicture}[auto, >=latex']
    % \draw [help lines] (-4,-2) grid (4,4);

    % Draw main axes
    \draw[->] (-4.2,0) -- (4.2,0) node[below] {\small Re($\sigma$)};
    \draw[->] (0,-2) -- (0,4.2) node[right] {\small Im($j\omega$)};

    % Stable: e^-1.75t * cos(1.75wt) (80/3*w for readability)
    \drawtimeplot{-2.125cm}{2.5cm}{0.125cm}{0.44375cm}{
      exp(-1.75 * \x) * cos(80/3 * 1.75 * deg(\x))}
    \drawpole{-1.75cm}{1.75cm}

    % Stable: e^-2.5t
    \drawtimeplot{-2.25cm}{0.75cm}{0.125cm}{0.125cm}{exp(-2 * \x)}
    \drawpole{-2cm}{0cm}

    % Stable: e^-t
    \drawtimeplot{-1.125cm}{-0.75cm}{0.125cm}{0.125cm}{exp(-\x)}
    \drawpole{-1cm}{0cm}

    % Marginally stable: cos(wt) (80/3*w for readability)
    \drawtimeplot{-0.75cm}{1.125cm}{0.125cm}{0.44375cm}{cos(80/3 * deg(\x))}
    \drawpole{0cm}{1cm}

    % Marginally stable cos(2wt) (80/3*w for readability)
    \drawtimeplot{0cm}{2.75cm}{0.125cm}{0.44375cm}{cos(80/3 * 2 * deg(\x))}
    \drawpole{0cm}{2cm}

    % Integrator
    \drawtimeplot{0.25cm}{-0.75cm}{0.125cm}{0.125cm}{1}
    \drawpole{0cm}{0cm}

    % Unstable: e^t
    \drawtimeplot{1.125cm}{0.75cm}{0.125cm}{0.125cm}{exp(\x)}
    \drawpole{1cm}{0cm}

    % Unstable: e^2t
    \drawtimeplot{2.25cm}{-0.75cm}{0.125cm}{0.125cm}{exp(2 * \x)}
    \drawpole{2cm}{0cm}

    % Unstable: e^0.75t * cos(1.75wt) (80/3*w for readability)
    \drawtimeplot{1.5cm}{2.25cm}{0.125cm}{0.44375cm}{
      exp(0.75 * \x) * cos(80/3 * 1.75 * deg(\x))}
    \drawpole{0.75cm}{1.75cm}

    % LHP and RHP labels
    \draw (-3.5,1.5) node {LHP};
    \draw (3.5,1.5) node {RHP};

    % Stable and unstable labels
    \draw (-2.5,3.5) node {\small Stable};
    \draw (2.5,3.5) node {\small Unstable};
  \end{tikzpicture}

  \caption{Time domain system response vs pole location}
  \label{fig:system_response_poles}
\end{bookfigure}

\begin{booktable}
  \begin{tabular}{|ll|}
    \hline
    \rowcolor{headingbg}
    \textbf{Location} & \textbf{Stability} \\
    \hline
    Left Half-plane (LHP) & Stable \\
    Imaginary axis & Marginally stable \\
    Right Half-plane (RHP) & Unstable \\
    \hline
  \end{tabular}

  \caption{Pole location and stability}
  \label{tab:pole_locations}
\end{booktable}

When a system is stable, its output may oscillate but it converges to
steady-state. When a system is marginally stable, its output oscillates at a
constant amplitude forever. When a system is unstable, its output grows without
bound. See figure \ref{fig:system_response_poles} for system responses with
hypothetical pole locations.

\section{Root locus}
\index{Stability!root locus}

In closed-loop, the poles can be moved around by adjusting the controller gain,
but the zeroes stay put. The root locus shows where the poles will go as the
gain for a P controller is increased and tells us for what range of gains the
controller will be stable. As the controller gain is increased, poles can move
toward negative infinity (figure \ref{fig:rlocus_infty}), move toward each other
then split toward asymptotes (figure \ref{fig:rlocus_asymptotes}), or move
toward zeroes (figure \ref{fig:rlocus_zeroes}).

\begin{figure}
  \begin{minisvg}{build/code/rlocus_infty}
    \caption{Root locus showing pole moving toward negative infinity.}
    \label{fig:rlocus_infty}
  \end{minisvg}
  \hfill
  \begin{minisvg}{build/code/rlocus_asymptotes}
    \caption{Root locus showing poles moving toward asymptotes.}
    \label{fig:rlocus_asymptotes}
  \end{minisvg}
  \begin{minisvg}{build/code/rlocus_zeroes}
    \caption{Root locus of equation (\ref{eq:transfer_func}) showing poles
      moving toward zeroes. Drawn using snippet \ref{lst:rlocus_zeroes}.}
    \label{fig:rlocus_zeroes}
  \end{minisvg}
\end{figure}

Root locus plots can be drawn using code like snippet \ref{lst:rlocus_zeroes}.

\begin{code}{Python}{code/rlocus_zeroes.py}
  \caption{Root locus in Python.}
  \label{lst:rlocus_zeroes}
\end{code}

In figure \ref{fig:rlocus_zeroes}, the poles orbit around a point toward the
zeroes and the \gls{system} eventually becomes unstable.

\begin{remark}
  If poles are much farther left in the LHP than the typical \gls{system}
  dynamics exhibit, they can be considered negligible. Every \gls{system} has
  some form of unmodeled high frequency, nonlinear dynamics, but they can be
  safely ignored depending on the operating regime.
\end{remark}

We won't cover PID control in relation to the root locus because classical
control isn't the focus of this book. However, we'll use the transfer function
for a PID controller later in the case studies.

\begin{equation*}
  K(s) = K_p + \frac{K_i}{s} + K_ds
\end{equation*}

\subsection{Non-minimum phase zeroes}

While poles in the RHP are unstable, the same is not true for zeroes. They can
be characterized by the \gls{system} initially moving in the wrong direction
before heading toward the \gls{reference}. Since the poles always move toward
the zeroes, zeroes impose a ``speed limit" on the \gls{system} response because
it takes a finite amount of time to move the wrong direction, then change
directions.

One example of this type of system is bicycle steering. Try riding a bicycle
without holding the handle bars, then poke the right handle; the bicycle turns
right. Conversely, if one is holding the handlebars and wants to turn left,
rotating the handlebars counterclockwise will make the bicycle fall toward the
right. The rider has to lean into the turn and overpower the non-minimum phase
dymamics to go the desired direction.

Another example is a segway. To move forward by some distance, the segway must
first roll backward to rotate the segway forward. Once the segway starts falling
in that direction, it begins rolling forward to avoid falling over until
it reaches the target distance. At that point, the segway increases its forward
speed to pitch backward and slow itself down. To come to a stop, the segway
rolls backward again to level itself out.

\section{Gain margin and phase margin} \label{sec:gain-phase-margin}
\index{Stability!gain margin}
\index{Stability!phase margin}

One generally needs to learn about Bode plots and Nyquist plots to truly
understand gain and phase margin and their origins, but those plots are large
topics unto themselves. Since we won't be using either of these plots for
controller design, we'll just cover what gain and phase margin are in a general
sense and how they are used.

Gain margin and phase margin are two metrics for measuring a system's relative
stability. Gain and phase margin are the amounts by which the closed-loop gain
and phase can be varied respectively before the system becomes unstable. In a
sense, they are safety margins for when unmodeled dynamics affect the system
response.

For a more thorough explanation of gain and phase margin, watch Brian Douglas's
video on them \cite{bib:gain_phase_margin}. He has other videos too on classical
control methods like Bode and Nyquist plots that we recommend.

\section{Case studies of Laplace domain analysis}

\subsection{Flywheel PID control}
\index{PID control}

PID controllers typically control voltage to a motor in FRC independent of the
equations of motion of that motor. For position PID control, large values of
$K_p$ can lead to overshoot and $K_d$ is commonly used to reduce overshoots.
Let's consider a flywheel controlled with a standard PID controller. Why
wouldn't $K_d$ provide damping for velocity overshoots in this case?

PID is designed to control second order and first order systems well. It can be
used to control a lot of things, but struggles when given higher order systems.
It has three degrees of freedom. Two are used to place the two poles of the
system, and the third is used to remove steady-state error. With higher order
systems like a one input, seven state system, there aren't enough degrees of
freedom to place the system's poles in desired locations. This will result in
poor control.

The math for PID doesn't assume voltage, a motor, etc. It defines an output
based on derivatives and integrals of the input. We happen to use it for motors
because it actually works pretty well for it because motors are second order
systems.

The following math will be in continuous time, but the same ideas apply to
discrete time. This is all assuming a velocity controller.

Our simple motor model hooked up to a mass is

\begin{align}
  V &= IR + \frac{\omega}{K_v} \label{eq:cs_flywheel_1} \\
  \tau &= I K_t \label{eq:cs_flywheel_2} \\
  \tau &= J \frac{d\omega}{dt} \label{eq:cs_flywheel_3}
\end{align}

First, we'll solve for $\frac{d\omega}{dt}$ in terms of $V$.

Substitute equation (\ref{eq:cs_flywheel_2}) into equation
 (\ref{eq:cs_flywheel_1}).

\begin{align*}
  V &= IR + \frac{\omega}{K_v} \\
  V &= \left(\frac{\tau}{K_t}\right) R + \frac{\omega}{K_v}
\end{align*}

Substitute in equation (\ref{eq:cs_flywheel_3}).

\begin{align*}
  V &= \frac{\left(J \frac{d\omega}{dt}\right)}{K_t} R + \frac{\omega}{K_v} \\
\end{align*}

Solve for $\frac{d\omega}{dt}$.

\begin{align*}
  V &= \frac{J \frac{d\omega}{dt}}{K_t} R + \frac{\omega}{K_v} \\
  V - \frac{\omega}{K_v} &= \frac{J \frac{d\omega}{dt}}{K_t} R \\
  \frac{d\omega}{dt} &= \frac{K_t}{JR} \left(V - \frac{\omega}{K_v}\right) \\
  \frac{d\omega}{dt} &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V
\end{align*}

Now take the Laplace transform.

\begin{equation}
  s \omega = -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V
  \label{eq:cs_motor_tf}
\end{equation}

Solve for the transfer function $H(s) = \frac{\omega}{V}$.

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V \\
  \left(s + \frac{K_t}{JRK_v}\right) \omega &= \frac{K_t}{JR} V \\
  \frac{\omega}{V} &= \frac{\frac{K_t}{JR}}{s + \frac{K_t}{JRK_v}} \\
\end{align*}

That gives us a pole at $-\frac{K_t}{JRK_v}$, which is actually stable. Notice
that there is only one pole.

First, we'll use a simple P loop (going to drive it to 0 without loss of
generality).

\begin{equation*}
  V = K_p (\omega_{goal} - \omega)
\end{equation*}

Substitute this controller into equation (\ref{eq:cs_motor_tf}).

\begin{equation*}
  s \omega = -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} K_p (\omega_{goal} -
    \omega)
\end{equation*}

Solve for the transfer function $H(s) = \frac{\omega}{\omega_{goal}}$.

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} (\omega_{goal} -
    \omega) \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} \omega_{goal} -
    \frac{K_t K_p}{JR} \omega \\
  \left(s + \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right) \omega &=
    \frac{K_t K_p}{JR} \omega_{goal} \\
  \frac{\omega}{\omega_{goal}} &= \frac{\frac{K_t K_p}{JR}}
    {\left(s + \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)} \\
\end{align*}

This has a pole at $-\left(\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)$.
Assuming that that quantity is negative (i.e., we are stable), that pole
corresponds to a time constant of
$\frac{1}{\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}}$.

As can be seen above, a flywheel has a single pole. It therefore only needs a
single pole controller to place all of its poles anywhere.

\begin{remark}
  This analysis assumes that the motor is well coupled to the mass and that the
  time constant of the inductor is fast enough that it doesn't factor into the
  motor equations. In Austin Schuh's experience with 971's robots, these are
  pretty good assumptions.
\end{remark}

Next, we'll try a PD loop. (This will use a perfect derivative, but anyone
following along closely already knows that we can't really take a derivative
here, so the math will need to be updated at some point. We could switch to
discrete time and pick a differentiation method, or pick some other way of
modeling the derivative.)

\begin{equation*}
  V = K_p (\omega_{goal} - \omega) + K_d s (\omega_{goal} - \omega)
\end{equation*}

Substitute this controller into equation (\ref{eq:cs_motor_tf}).

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR}
    \left(K_p (\omega_{goal} - \omega) + K_d s (\omega_{goal} - \omega)\right)
    \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR}
    (\omega_{goal} - \omega) + \frac{K_t K_d s}{JR} (\omega_{goal} - \omega) \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} \omega_{goal} -
    \frac{K_t K_p}{JR} \omega + \frac{K_t K_d s}{JR} \omega_{goal} -
    \frac{K_t K_d s}{JR} \omega \\
\end{align*}

Collect the common terms on separate sides and refactor.

\begin{align*}
  s \omega + \frac{K_t K_d s}{JR} \omega + \frac{K_t}{JRK_v} \omega +
    \frac{K_t K_p}{JR} \omega &= \frac{K_t K_p}{JR} \omega_{goal} +
    \frac{K_t K_d s}{JR} \omega_{goal} \\
  \left(s \left(1 + \frac{K_t K_d}{JR}\right) + \frac{K_t}{JRK_v} +
    \frac{K_t K_p}{JR}\right) \omega &= \frac{K_t}{JR}
    \left(K_p + K_d s\right) \omega_{goal} \\
  \frac{\omega}{\omega_{goal}} &= \frac{\frac{K_t}{JR}
    \left(K_p + K_d s\right)}{\left(s \left(1 + \frac{K_t K_d}{JR}\right) +
    \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)} \\
\end{align*}

So, we added a zero at $-\frac{K_p}{K_d}$ and moved our pole to
$-\frac{\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}}{1 + \frac{K_t K_d}{JR}}$. This
isn't progress. We've added more complexity to our system and, practically
speaking, gotten nothing good out of it. Zeros should be avoided if at all
possible because they amplify unwanted high frequency modes of the system. At
least this is a stable zero, but still.

In summary, derivative doesn't help on a flywheel. $K_d$ may help if the real
system isn't ideal, but we don't suggest relying on that.

\subsection{Steady-state error}
\index{Steady-state error}

To demonstrate the problem of \gls{steady-state error}, we will use a DC brushed
motor controlled by a velocity PID controller. A DC brushed motor has a transfer
function from voltage ($V$) to angular velocity ($\dot{\theta}$) of

\begin{equation}
  G(s) = \frac{\dot{\Theta}(s)}{V(s)} = \frac{K}{(Js+b)(Ls+R)+K^2}
\end{equation}

First, we'll try controlling it with a P controller defined as

\begin{equation*}
  K(s) = K_p
\end{equation*}

When these are in unity feedback, the transfer function from the input voltage
to the error is

\begin{align*}
  \frac{E(s)}{V(s)} &= \frac{1}{1 + K(s)G(s)} \\
  E(s) &= \frac{1}{1 + K(s)G(s)} V(s) \\
  E(s) &= \frac{1}{1 + (K_p) \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} V(s) \\
  E(s) &= \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}} V(s)
\end{align*}

The steady-state of a transfer function can be found via

\begin{equation}
  \lim_{s\to0} sH(s)
\end{equation}

\begin{align}
  e_{ss} &= \lim_{s\to0} sE(s) \nonumber \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}} V(s)
    \nonumber \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}}
    \frac{1}{s} \nonumber \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}}
    \nonumber \\
  e_{ss} &= \frac{1}{1 + \frac{K_p K}{(J(0)+b)(L(0)+R)+K^2}} \nonumber \\
  e_{ss} &= \frac{1}{1 + \frac{K_p K}{bR+K^2}} \label{eq:ss_nonzero}
\end{align}

Notice that the \gls{steady-state error} is nonzero. To fix this, an integrator
must be included in the controller.

\begin{equation*}
  K(s) = K_p + \frac{K_i}{s}
\end{equation*}

The same steady-state calculations are performed as before with the new
controller.

\begin{align*}
  \frac{E(s)}{V(s)} &= \frac{1}{1 + K(s)G(s)} \\
  E(s) &= \frac{1}{1 + K(s)G(s)} V(s) \\
  E(s) &= \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \left(\frac{1}{s}\right) \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \left(\frac{1}{s}\right) \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \frac{s}{s} \\
  e_{ss} &= \lim_{s\to0} \frac{s}{s + \left(K_p s + K_i\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \\
  e_{ss} &= \frac{0}{0 + (K_p (0) + K_i)
    \left(\frac{K}{(J(0)+b)(L(0)+R)+K^2}\right)} \\
  e_{ss} &= \frac{0}{K_i \frac{K}{bR+K^2}}
\end{align*}

The denominator is nonzero, so $e_{ss} = 0$. Therefore, an integrator is
required to eliminate \gls{steady-state error} in all cases for this
\gls{model}.

It should be noted that $e_{ss}$ in equation (\ref{eq:ss_nonzero}) approaches
zero for $K_p = \infty$. This is known as a bang-bang controller. In practice,
an infinite switching frequency cannot be achieved, but it may be close enough
for some performance specifications.
