\chapterimage{laplace-domain-analysis.jpg}{Grass clearing by Interdisciplinary Sciences building and Thimann Labs at UCSC}

\chapter{Laplace domain analysis}

This chapter briefly discusses what transfer functions are, how the locations of
poles and zeroes affects system response and stability, and how controllers
affect pole locations. The case studies cover various aspects of PID control
using the algebraic approach of transfer functions.

\section{The Fourier transform}

The Fourier transform decomposes a function of time into its component
frequencies. Each of these frequencies is part of what's called a
\textit{basis}. These waveforms can be added together in linear combinations to
produce the original signal. That is, we create a sum of waveforms that are
multiplied by their respective contribution amount.

Think of an F major 4 chord which has the notes $F_4$ ($349.23\,Hz$), $A_4$
($440\,Hz$), and $C_4$ ($261.63\,Hz$). The waveform over time looks like figure
\ref{fig:fourier_chord}.

\begin{svg}{build/code/fourier_chord}
  \caption{Frequency decomposition of Fmajor4 chord}
  \label{fig:fourier_chord}
\end{svg}

Notice how this complex waveform can be represented just by three frequencies.
They show up as Dirac delta functions\footnote{The Dirac delta function is zero
everywhere except near the origin. The nonzero region has an infinitesimal width
and a height such that the area within that region is $1$.} in the frequency
domain with the area underneath them equal to their contribution (see figure
\ref{fig:fourier_chord_fft}).

\begin{svg}{build/code/fourier_chord_fft}
  \caption{Fourier transform of Fmajor4 chord}
  \label{fig:fourier_chord_fft}
\end{svg}

In summary, the Fourier transform provides a way for us to determine, given some
signal, what frequencies can we add together and in what amounts to produce the
original signal.

\section{The Laplace domain}

The Laplace domain is a generalization of the frequency domain that has the
frequency ($j\omega$) on the imaginary y-axis and a real number on the x-axis,
yielding a two-dimensional coordinate system. We represent coordinates in this
space as a complex number $s = \sigma + j\omega$. The real part $\sigma$
cooresponds to the x-axis and the imaginary part $j\omega$ cooresponds to the
y-axis (see figure \ref{fig:laplace_domain}).

\begin{bookfigure}
  \begin{tikzpicture}[auto, >=latex']
    %\draw [help lines] (-4,-2) grid (4,4);

    % Draw main axes
    \draw[<->] (-4.2,1) -- (4.2,1) node[below] {\small Re($\sigma$)};
    \draw[<->] (0,-2) -- (0,4.2) node[right] {\small Im($j\omega$)};
  \end{tikzpicture}

  \caption{Laplace domain}
  \label{fig:laplace_domain}
\end{bookfigure}

To extend our analogy of each coordinate being represented by some basis, we now
have the y coordinate representing the oscillation frequency of the system
response (the frequency domain) and also the x coordinate representing the speed
at which that oscillation decays and the system converges to zero. Figure
\ref{fig:impulse_response_poles} shows this for various points.

Note that this explanation as a basis isn't exact because the Laplace basis
isn't orthogonal (that is, the x and y coordinates affect each other and have
cross-talk). In the frequency domain, we had a basis of sine waves that we
represented as delta functions in the frequency domain. Each frequency
contribution was independent of the others. In the Laplace domain, this is not
the case; a pure exponential is $\frac{1}{s -a}$ (a rational function) instead
of a delta function. This function is nonzero at points that aren't actually
frequencies present in the time domain.

\section{The Laplace transform}

The Laplace transform of a function $f(t)$ is defined as

\begin{equation*}
  \mathcal{L}\{f(t)\} = F(s) = \int_0^\infty f(t) e^{-st} \,dt
\end{equation*}

Common Laplace transforms (assuming zero initial conditions) are shown in table
\ref{tab:common-laplace-transforms}. Of particular note are the Laplace
transforms for the derivative, unit step\footnote{The unit step $u(t)$ is
defined as $0$ for $t < 0$ and $1$ for $t \ge 0$.}, and exponential decay. We
can see that a derivative is equivalent to multiplying by $s$, and an integral
is equivalent to multiplying by $\frac{1}{s}$. We'll discuss the decaying
exponential shortly.

\begin{booktable}
  \begin{tabular}{|ccc|}
    \hline
    \rowcolor{headingbg}
    & \textbf{Time domain} & \textbf{Laplace domain} \\
    \hline
    Linearity & $a\,f(t) + b\,g(t)$ & $a\,F(s) + b\,G(s)$ \\
    Convolution & $(f * g)(t)$ & $F(s) \,G(s)$ \\
    Derivative & $f'(t)$ & $s \,F(s)$ \\
    $n^{th}$ derivative & $f^{(n)}(t)$ & $s^n \,F(s)$ \\
    Unit step & $u(t)$ & $\frac{1}{s}$ \\
    Ramp & $t \,u(t)$ & $\frac{1}{s^2}$ \\
    Exponential decay & $e^{-\alpha t} u(t)$ & $\frac{1}{s + \alpha}$ \\
    \hline
  \end{tabular}
  \caption{Common Laplace transforms and Laplace transform properties with zero
    initial conditions}
  \label{tab:common-laplace-transforms}
\end{booktable}

\section{Transfer functions, poles, and zeroes}

A transfer function maps an input coordinate to an output coordinate in the
Laplace domain. These can be obtained by applying the Laplace transform to a
differential equation and rearranging the terms to obtain a ratio of the output
variable to the input variable. Equation (\ref{eq:transfer_func}) is an example
of a transfer function.

\begin{equation} \label{eq:transfer_func}
  H(s) = \frac{(s-9+9i)(s-9-9i)}{s(s+10)}
\end{equation}

The roots of factors in the numerator of a transfer function are called
\textit{zeroes} because they make the transfer function approach zero. Likewise,
the roots of factors in the denominator of a transfer function are called
\textit{poles} because they make the transfer function approach infinity; on a
3D graph, these look like the poles of a circus tent. See figure
\ref{fig:tf_3d}.

When the factors of the denominator are broken apart using partial fraction
expansion into something like $\frac{A}{s + a} + \frac{B}{s + b}$, the constants
$A$ and $B$ are called residues, which determine how much each pole contributes
to the system response.

You may notice that the factors representing poles look a lot like the Laplace
transform for a decaying exponential. This is why the time domain responses of
systems are typically decaying exponentials. One differential equation which can
produce this kind of response is $\dot{x} = ax$ where $\dot{x}$ is the
derivative of $x$ and $a < 0$.

\begin{svg}{build/code/tf_3d}
  \caption{Equation \ref{eq:transfer_func} plotted in 3D}
  \label{fig:tf_3d}
\end{svg}

\begin{remark}
  Imaginary poles and zeroes always come in complex conjugate pairs (e.g.,
  $-2 + 3i$, $-2 - 3i$).
\end{remark}

\section{Transfer functions in feedback}

For \glspl{controller} to \glslink{regulator}{regulate} a system or
\glslink{tracking}{track} a reference, they must be placed in positive or
negative feedback with the \gls{plant} (whether to use positive or negative
depends on the \gls{plant} in question). Stable feedback loops attempt to make
the \gls{output} equal the \gls{reference}.

\begin{bookfigure}
  \begin{tikzpicture}[auto, >=latex']
    % Place the blocks
    \node [name=input] {$X(s)$};
    \node [sum, right=of input] (sum) {};
    \node [block, right=of sum] (K) {$K$};
    \node [block, right=of K] (G) {$G$};
    \node [right=of G] (output) {$Y(s)$};
    \node [block, below=of $(K)!0.5!(G)$] (H) {$H$};

    % Connect the nodes
    \draw [arrow] (input) -- node[pos=0.85] {$+$} (sum);
    \draw [arrow] (sum) -- node {} (K);
    \draw [arrow] (K) -- node {} (G);
    \draw [arrow] (G) -- node[name=y] {} (output);
    \draw [arrow] (y) |- (H);
    \draw [arrow] (H) -| node[pos=0.97, right] {$-$} (sum);
  \end{tikzpicture}

  \caption{Feedback controller block diagram}
  \label{fig:feedback_controller_block_diagram}

  \begin{figurekey}
    \begin{tabulary}{\linewidth}{LLLL}
      $X(s)$ & input & $H$ & measurement transfer function \\
      $K$ & controller gain & $Y(s)$ & output \\
      $G$ & plant transfer function & & \\
    \end{tabulary}
  \end{figurekey}
\end{bookfigure}

The transfer function of figure \ref{fig:feedback_controller_block_diagram}, a
control system diagram with feedback, from input to output is

\begin{equation}
  G_{cl}(s) = \frac{Y(s)}{X(s)} = \frac{KG}{1 + KGH}
\end{equation}

The numerator is the \gls{open-loop gain} and the denominator is one plus the
gain around the feedback loop, which may include parts of the
\gls{open-loop gain} (see appendix \ref{sec:deriv-tf-feedback} for a
derivation). As another example, the transfer function from the input to the
error is

\begin{equation}
  G_{cl}(s) = \frac{E(s)}{X(s)} = \frac{1}{1 + KGH}
\end{equation}

The roots of the denominator of $G_{cl}(s)$ are different from those of the
open-loop transfer function $KG(s)$. These are called the closed-loop poles.

\section{Locations of poles and zeroes}
\index{Stability!poles and zeroes}

The locations of the closed-loop poles in the complex plane determine the
stability of the \gls{system}. Each pole represents a frequency mode of the
\gls{system}, and their location determines how much of each response is induced
for a given input frequency. Figure \ref{fig:impulse_response_poles} shows the
impulse responses\footnote{An impulse response is the response of a \gls{system}
to the Dirac delta function.} in the time domain for transfer functions with
various pole locations. They all have an initial condition of one.

\begin{bookfigure}
  \begin{tikzpicture}[auto, >=latex']
    % \draw [help lines] (-4,-2) grid (4,4);

    % Draw main axes
    \draw[->] (-4.2,0) -- (4.2,0) node[below] {\small Re($\sigma$)};
    \draw[->] (0,-2) -- (0,4.2) node[right] {\small Im($j\omega$)};

    % Stable: e^-1.75t * cos(1.75wt) (80/3*w for readability)
    \drawtimeplot{-2.125cm}{2.5cm}{0.125cm}{0.44375cm}{
      exp(-1.75 * \x) * cos(80/3 * 1.75 * deg(\x))}
    \drawpole{-1.75cm}{1.75cm}

    % Stable: e^-2.5t
    \drawtimeplot{-2.25cm}{0.75cm}{0.125cm}{0.125cm}{exp(-2 * \x)}
    \drawpole{-2cm}{0cm}

    % Stable: e^-t
    \drawtimeplot{-1.125cm}{-0.75cm}{0.125cm}{0.125cm}{exp(-\x)}
    \drawpole{-1cm}{0cm}

    % Marginally stable: cos(wt) (80/3*w for readability)
    \drawtimeplot{-0.75cm}{1.125cm}{0.125cm}{0.44375cm}{cos(80/3 * deg(\x))}
    \drawpole{0cm}{1cm}

    % Marginally stable cos(2wt) (80/3*w for readability)
    \drawtimeplot{0cm}{2.75cm}{0.125cm}{0.44375cm}{cos(80/3 * 2 * deg(\x))}
    \drawpole{0cm}{2cm}

    % Integrator
    \drawtimeplot{0.25cm}{-0.75cm}{0.125cm}{0.125cm}{1}
    \drawpole{0cm}{0cm}

    % Unstable: e^t
    \drawtimeplot{1.125cm}{0.75cm}{0.125cm}{0.125cm}{exp(\x)}
    \drawpole{1cm}{0cm}

    % Unstable: e^2t
    \drawtimeplot{2.25cm}{-0.75cm}{0.125cm}{0.125cm}{exp(2 * \x)}
    \drawpole{2cm}{0cm}

    % Unstable: e^0.75t * cos(1.75wt) (80/3*w for readability)
    \drawtimeplot{1.5cm}{2.25cm}{0.125cm}{0.44375cm}{
      exp(0.75 * \x) * cos(80/3 * 1.75 * deg(\x))}
    \drawpole{0.75cm}{1.75cm}

    % LHP and RHP labels
    \draw (-3.5,1.5) node {LHP};
    \draw (3.5,1.5) node {RHP};

    % Stable and unstable labels
    \draw (-2.5,3.5) node {\small Stable};
    \draw (2.5,3.5) node {\small Unstable};
  \end{tikzpicture}

  \caption{Impulse response vs pole location}
  \label{fig:impulse_response_poles}
\end{bookfigure}

\begin{booktable}
  \begin{tabular}{|ll|}
    \hline
    \rowcolor{headingbg}
    \textbf{Location} & \textbf{Stability} \\
    \hline
    Left Half-plane (LHP) & Stable \\
    Imaginary axis & Marginally stable \\
    Right Half-plane (RHP) & Unstable \\
    \hline
  \end{tabular}

  \caption{Pole location and stability}
  \label{tab:pole_locations}
\end{booktable}

When a system is stable, its output may oscillate but it converges to
steady-state. When a system is marginally stable, its output oscillates at a
constant amplitude forever. When a system is unstable, its output grows without
bound.

\subsection{Non-minimum phase zeroes}

While poles in the RHP are unstable, the same is not true for zeroes. They can
be characterized by the \gls{system} initially moving in the wrong direction
before heading toward the \gls{reference}. Since the poles always move toward
the zeroes, zeroes impose a ``speed limit" on the \gls{system} response because
it takes a finite amount of time to move the wrong direction, then change
directions.

One example of this type of system is bicycle steering. Try riding a bicycle
without holding the handle bars, then poke the right handle; the bicycle turns
right. Furthermore, if one is holding the handlebars and wants to turn left,
rotating the handlebars counterclockwise will make the bicycle fall toward the
right. The rider has to lean into the turn and overpower the non-minimum phase
dymamics to go the desired direction.

Another example is a segway. To move forward by some distance, the segway must
first roll backward to rotate the segway forward. Once the segway starts falling
in that direction, it begins rolling forward to avoid falling over until
it reaches the target distance. At that point, the segway increases its forward
speed to pitch backward and slow itself down. To come to a stop, the segway
rolls backward again to level itself out.

\section{Root locus} \label{sec:root_locus}
\index{Stability!root locus}

In closed-loop, the poles can be moved around by adjusting the controller gain,
but the zeroes stay put. The root locus shows where the poles will go as the
gain for a P controller is increased and tells us for what range of gains the
controller will be stable. As the controller gain is increased, poles can move
toward negative infinity (figure \ref{fig:rlocus_infty}), move toward each other
then split toward asymptotes (figure \ref{fig:rlocus_asymptotes}), or move
toward zeroes (figure \ref{fig:rlocus_zeroes}). The \gls{system} in figure
\ref{fig:rlocus_zeroes} becomes unstable as the gain is increased.

\begin{bookfigure}
  \begin{minisvg}{build/code/rlocus_infty}
    \caption{Root locus showing pole moving toward negative infinity}
    \label{fig:rlocus_infty}
  \end{minisvg}
  \hfill
  \begin{minisvg}{build/code/rlocus_asymptotes}
    \caption{Root locus showing poles moving toward asymptotes}
    \label{fig:rlocus_asymptotes}
  \end{minisvg}
  \hfill
  \begin{minisvg}{build/code/rlocus_zeroes}
    \caption{Root locus of equation (\ref{eq:transfer_func}) showing poles
      moving toward zeroes.}
    \label{fig:rlocus_zeroes}
  \end{minisvg}
\end{bookfigure}

We won't be using root locus plots for any of our control systems analysis
later, but it does help provide an intuition for what controllers actually do to
a system.

If poles are much farther left in the LHP than the typical \gls{system} dynamics
exhibit, they can be considered negligible. Every \gls{system} has some form of
unmodeled high frequency, nonlinear dynamics, but they can be safely ignored
depending on the operating regime.

To demonstrate this, consider the transfer function for a second-order DC
brushed motor from voltage to position

\begin{equation*}
  G(s) = \frac{K}{s((Js + b)(Ls + R) + K^2)}
\end{equation*}

where $J = 3.2284 \times 10^{-6}$ $kg$-$m^2$, $b = 3.5077 \times 10^{-6}$
$N$-$m$-$s$, $K_e = K_t = 0.0274 \,V/rad/s$, $R = 4 \,\Omega$, and
$L = 2.75 \times 10^{-6} \,H$.

This plant has the root locus shown in figure
\ref{fig:highfreq_unstable_rlocus}. In proportional feedback, the plant is
unstable for large values of $K$. However, if we remove the unstable pole by
setting $L$ in the transfer function to zero, we get the root locus in figure
\ref{fig:highfreq_stable_rlocus}. For small values of $K$, both systems are
stable and have nearly indistinguishable step responses due to the exceedingly
small contribution from the fast pole (see figures
\ref{fig:highfreq_unstable_step} and \ref{fig:highfreq_stable_step}). The high
frequency dynamics only cause instability for large values of $K$ that induce
fast system responses. In other words, the system responses of the second-order
model and its first-order approximation are similar for low frequency operating
regimes.

\begin{bookfigure}
  \begin{minisvg}{build/code/highfreq_unstable_rlocus}
    \caption{Root locus of second-order DC brushed motor plant}
    \label{fig:highfreq_unstable_rlocus}
  \end{minisvg}
  \hfill
  \begin{minisvg}{build/code/highfreq_stable_rlocus}
    \caption{Root locus of first-order DC brushed motor plant}
    \label{fig:highfreq_stable_rlocus}
  \end{minisvg}
\end{bookfigure}

\begin{bookfigure}
  \begin{minisvg}{build/code/highfreq_unstable_step}
    \caption{Step response of second-order DC brushed motor plant}
    \label{fig:highfreq_unstable_step}
  \end{minisvg}
  \hfill
  \begin{minisvg}{build/code/highfreq_stable_step}
    \caption{Step response of first-order DC brushed motor plant}
    \label{fig:highfreq_stable_step}
  \end{minisvg}
\end{bookfigure}

Why can't unstable poles close to the origin be ignored in the same way? The
response of high frequency stable poles decays rapidly. Unstable poles, on the
other hand, represent unstable dynamics which cause the system output to grow to
infinity. Regardless of how slow these unstable dynamics are, they will
eventually dominate the response.

\section{Pole-zero cancellation}

Pole-zero cancellation occurs when a pole and zero are located at the same place
in the s-plane. This effectively eliminates the contribution of each to the
system dynamics. By placing poles and zeroes at various locations, we can
eliminate undesired system dynamics. While this may appear to be a useful design
tool at first, there are major caveats. Most of these are due to model
uncertainty resulting in poles which aren't in the locations the controls
designer expected.

Notch filters are typically used to dampen a specific range of frequencies in
the system response. If its band is made too narrow, it can still leave the
undesirable dynamics, but now you can no longer measure them in the response.
They are still happening, but they are what's called \textit{unobservable}.

Never pole-zero cancel unstable or non-minimum phase dynamics. If the model
doesn't quite reflect reality, an attempted pole cancellation by placing a
non-minimum phase zero results in the pole still moving to the zero placed next
to it. You have the same dynamics as before, but the pole is also stuck where it
is no matter how much feedback gain is applied. For an attempted non-minimum
phase zero cancellation, you have effectively placed an unstable pole that's
unobservable. This means the system will be going unstable and blowing up, but
you won't be able to detect this and react to it.

Keep in mind when making design decisions that the model likely isn't perfect.
The whole point of feedback control is to be robust to this kind of uncertainty.

\section{Gain margin and phase margin} \label{sec:gain-phase-margin}
\index{Stability!gain margin}
\index{Stability!phase margin}

One generally needs to learn about Bode plots and Nyquist plots to truly
understand gain and phase margin and their origins, but those plots are large
topics unto themselves. Since we won't be using either of these plots for
controller design, we'll just cover what gain and phase margin are in a general
sense and how they are used. We'll be discussing how discretization affects
phase margin in section \ref{sec:phase_loss}.

Gain margin and phase margin are two metrics for measuring a system's relative
stability. Gain and phase margin are the amounts by which the closed-loop gain
and phase can be varied respectively before the system becomes unstable. In a
sense, they are safety margins for when unmodeled dynamics affect the system
response.

For a more thorough explanation of gain and phase margin, watch Brian Douglas's
video on them \cite{bib:gain_phase_margin}. He has other videos too on classical
control methods like Bode and Nyquist plots that we recommend.

\section{Case studies of Laplace domain analysis}

We'll be using equation (\ref{eq:pid_tf}), the transfer function for a PID
controller, in the case studies.

\begin{equation}
  K(s) = K_p + \frac{K_i}{s} + K_ds \label{eq:pid_tf}
\end{equation}

\subsection{Flywheel PID control} \label{subsec:flywheel-pid-control}
\index{PID control}

PID controllers typically control voltage to a motor in FRC independent of the
equations of motion of that motor. For position PID control, large values of
$K_p$ can lead to overshoot and $K_d$ is commonly used to reduce overshoots.
Let's consider a flywheel controlled with a standard PID controller. Why
wouldn't $K_d$ provide damping for velocity overshoots in this case?

PID control is designed to control second-order and first-order systems well. It
can be used to control a lot of things, but struggles when given higher order
systems. It has three degrees of freedom. Two are used to place the two poles of
the system, and the third is used to remove steady-state error. With higher
order systems like a one input, seven state system, there aren't enough degrees
of freedom to place the system's poles in desired locations. This will result in
poor control.

The math for PID doesn't assume voltage, a motor, etc. It defines an output
based on derivatives and integrals of the input. We happen to use it for motors
because it actually works pretty well for it because motors are second-order
systems.

The following math will be in continuous time, but the same ideas apply to
discrete time. This is all assuming a velocity controller.

Our simple motor model hooked up to a mass is

\begin{align}
  V &= IR + \frac{\omega}{K_v} \label{eq:cs_flywheel_1} \\
  \tau &= I K_t \label{eq:cs_flywheel_2} \\
  \tau &= J \frac{d\omega}{dt} \label{eq:cs_flywheel_3}
\end{align}

First, we'll solve for $\frac{d\omega}{dt}$ in terms of $V$.

Substitute equation (\ref{eq:cs_flywheel_2}) into equation
 (\ref{eq:cs_flywheel_1}).

\begin{align*}
  V &= IR + \frac{\omega}{K_v} \\
  V &= \left(\frac{\tau}{K_t}\right) R + \frac{\omega}{K_v}
\end{align*}

Substitute in equation (\ref{eq:cs_flywheel_3}).

\begin{align*}
  V &= \frac{\left(J \frac{d\omega}{dt}\right)}{K_t} R + \frac{\omega}{K_v} \\
\end{align*}

Solve for $\frac{d\omega}{dt}$.

\begin{align*}
  V &= \frac{J \frac{d\omega}{dt}}{K_t} R + \frac{\omega}{K_v} \\
  V - \frac{\omega}{K_v} &= \frac{J \frac{d\omega}{dt}}{K_t} R \\
  \frac{d\omega}{dt} &= \frac{K_t}{JR} \left(V - \frac{\omega}{K_v}\right) \\
  \frac{d\omega}{dt} &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V
\end{align*}

Now take the Laplace transform.

\begin{equation}
  s \omega = -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V
  \label{eq:cs_motor_tf}
\end{equation}

Solve for the transfer function $H(s) = \frac{\omega}{V}$.

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V \\
  \left(s + \frac{K_t}{JRK_v}\right) \omega &= \frac{K_t}{JR} V \\
  \frac{\omega}{V} &= \frac{\frac{K_t}{JR}}{s + \frac{K_t}{JRK_v}} \\
\end{align*}

That gives us a pole at $-\frac{K_t}{JRK_v}$, which is actually stable. Notice
that there is only one pole.

First, we'll use a simple P loop (going to drive it to 0 without loss of
generality).

\begin{equation*}
  V = K_p (\omega_{goal} - \omega)
\end{equation*}

Substitute this controller into equation (\ref{eq:cs_motor_tf}).

\begin{equation*}
  s \omega = -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} K_p (\omega_{goal} -
    \omega)
\end{equation*}

Solve for the transfer function $H(s) = \frac{\omega}{\omega_{goal}}$.

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} (\omega_{goal} -
    \omega) \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} \omega_{goal} -
    \frac{K_t K_p}{JR} \omega \\
  \left(s + \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right) \omega &=
    \frac{K_t K_p}{JR} \omega_{goal} \\
  \frac{\omega}{\omega_{goal}} &= \frac{\frac{K_t K_p}{JR}}
    {\left(s + \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)} \\
\end{align*}

This has a pole at $-\left(\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)$.
Assuming that that quantity is negative (i.e., we are stable), that pole
corresponds to a time constant of
$\frac{1}{\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}}$.

As can be seen above, a flywheel has a single pole. It therefore only needs a
single pole controller to place all of its poles anywhere.

\begin{remark}
  This analysis assumes that the motor is well coupled to the mass and that the
  time constant of the inductor is small enough that it doesn't factor into the
  motor equations. In Austin Schuh's experience with 971's robots, these are
  pretty good assumptions.
\end{remark}

Next, we'll try a PD loop. (This will use a perfect derivative, but anyone
following along closely already knows that we can't really take a derivative
here, so the math will need to be updated at some point. We could switch to
discrete time and pick a differentiation method, or pick some other way of
modeling the derivative.)

\begin{equation*}
  V = K_p (\omega_{goal} - \omega) + K_d s (\omega_{goal} - \omega)
\end{equation*}

Substitute this controller into equation (\ref{eq:cs_motor_tf}).

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR}
    \left(K_p (\omega_{goal} - \omega) + K_d s (\omega_{goal} - \omega)\right)
    \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR}
    (\omega_{goal} - \omega) + \frac{K_t K_d s}{JR} (\omega_{goal} - \omega) \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} \omega_{goal} -
    \frac{K_t K_p}{JR} \omega + \frac{K_t K_d s}{JR} \omega_{goal} -
    \frac{K_t K_d s}{JR} \omega \\
\end{align*}

Collect the common terms on separate sides and refactor.

\begin{align*}
  s \omega + \frac{K_t K_d s}{JR} \omega + \frac{K_t}{JRK_v} \omega +
    \frac{K_t K_p}{JR} \omega &= \frac{K_t K_p}{JR} \omega_{goal} +
    \frac{K_t K_d s}{JR} \omega_{goal} \\
  \left(s \left(1 + \frac{K_t K_d}{JR}\right) + \frac{K_t}{JRK_v} +
    \frac{K_t K_p}{JR}\right) \omega &= \frac{K_t}{JR}
    \left(K_p + K_d s\right) \omega_{goal} \\
  \frac{\omega}{\omega_{goal}} &= \frac{\frac{K_t}{JR}
    \left(K_p + K_d s\right)}{\left(s \left(1 + \frac{K_t K_d}{JR}\right) +
    \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)} \\
\end{align*}

So, we added a zero at $-\frac{K_p}{K_d}$ and moved our pole to
$-\frac{\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}}{1 + \frac{K_t K_d}{JR}}$. This
isn't progress. We've added more complexity to our system and, practically
speaking, gotten nothing good out of it. Zeroes should be avoided if at all
possible because they amplify unwanted high frequency modes of the system. At
least this is a stable zero, but still.

In summary, derivative doesn't help on a flywheel. $K_d$ may help if the real
system isn't ideal, but we don't suggest relying on that.

\subsection{Steady-state error}
\index{Steady-state error}

To demonstrate the problem of \gls{steady-state error}, we will use a DC brushed
motor controlled by a velocity PID controller. A DC brushed motor has a transfer
function from voltage ($V$) to angular velocity ($\dot{\theta}$) of

\begin{equation}
  G(s) = \frac{\dot{\Theta}(s)}{V(s)} = \frac{K}{(Js+b)(Ls+R)+K^2}
\end{equation}

First, we'll try controlling it with a P controller defined as

\begin{equation*}
  K(s) = K_p
\end{equation*}

When these are in unity feedback, the transfer function from the input voltage
to the error is

\begin{align*}
  \frac{E(s)}{V(s)} &= \frac{1}{1 + K(s)G(s)} \\
  E(s) &= \frac{1}{1 + K(s)G(s)} V(s) \\
  E(s) &= \frac{1}{1 + (K_p) \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} V(s) \\
  E(s) &= \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}} V(s)
\end{align*}

The steady-state of a transfer function can be found via

\begin{equation}
  \lim_{s\to0} sH(s)
\end{equation}

\begin{align}
  e_{ss} &= \lim_{s\to0} sE(s) \nonumber \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}} V(s)
    \nonumber \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}}
    \frac{1}{s} \nonumber \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}}
    \nonumber \\
  e_{ss} &= \frac{1}{1 + \frac{K_p K}{(J(0)+b)(L(0)+R)+K^2}} \nonumber \\
  e_{ss} &= \frac{1}{1 + \frac{K_p K}{bR+K^2}} \label{eq:ss_nonzero}
\end{align}

Notice that the \gls{steady-state error} is nonzero. To fix this, an integrator
must be included in the controller.

\begin{equation*}
  K(s) = K_p + \frac{K_i}{s}
\end{equation*}

The same steady-state calculations are performed as before with the new
controller.

\begin{align*}
  \frac{E(s)}{V(s)} &= \frac{1}{1 + K(s)G(s)} \\
  E(s) &= \frac{1}{1 + K(s)G(s)} V(s) \\
  E(s) &= \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \left(\frac{1}{s}\right) \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \left(\frac{1}{s}\right) \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \frac{s}{s} \\
  e_{ss} &= \lim_{s\to0} \frac{s}{s + \left(K_p s + K_i\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \\
  e_{ss} &= \frac{0}{0 + (K_p (0) + K_i)
    \left(\frac{K}{(J(0)+b)(L(0)+R)+K^2}\right)} \\
  e_{ss} &= \frac{0}{K_i \frac{K}{bR+K^2}}
\end{align*}

The denominator is nonzero, so $e_{ss} = 0$. Therefore, an integrator is
required to eliminate \gls{steady-state error} in all cases for this
\gls{model}.

It should be noted that $e_{ss}$ in equation (\ref{eq:ss_nonzero}) approaches
zero for $K_p = \infty$. This is known as a bang-bang controller. In practice,
an infinite switching frequency cannot be achieved, but it may be close enough
for some performance specifications.

\subsection{Actuator saturation}
\index{Controller design!actuator saturation}

Recall that a controller calculates its output based on the error between the
reference and the current state. Plants in the real world don't have unlimited
control authority available for the controller to apply. When the actuator
limits are reached, the controller acts as if the gain has been temporarily
reduced.

We'll try to explain this through a bit of math. Let's say we have a controller
$u = k(r - x)$ where $u$ is the control effort, $k$ is the gain, $r$ is the
reference, and $x$ is the current state. Let $u_{max}$ be the limit of the
actuator's output which is less than the uncapped value of $u$ and $k_{max}$ be
the associated maximum gain. We will now compare the capped and uncapped
controllers for the same reference and current state.

\begin{align*}
  u_{max} &< u \\
  k_{max}(r - x) &< k(r - x) \\
  k_{max} &< k
\end{align*}

For the inequality to hold, $k_{max}$ must be less than the original value for
$k$. This reduced gain is evident in a system response when there is a linear
change in state instead of an exponential one as it approaches the reference.
This is due to the control effort no longer following a decaying exponential
plot. Once the system is closer to the reference, the controller will stop
saturating and produce realistic controller values again.
