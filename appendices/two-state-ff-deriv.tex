\chapter{Two-state feedforward derivation} \label{ch:app-two-state-ff-deriv}

Let's start with the equation for the reference dynamics

\begin{equation*}
  \mtx{r}_{k+1} = \mtx{A}\mtx{r}_k + \mtx{B}\mtx{u}_{ff}
\end{equation*}

where $\mtx{u}_{ff}$ is the feedforward input. Note that this feedforward
equation does not and should not take into account any feedback terms. We want
to find the optimal $\mtx{u}_{ff}$ such that we minimize the tracking error
between $\mtx{r}_{k+1}$ and $\mtx{r}_k$.

\begin{equation*}
  \mtx{r}_{k+1} - \mtx{A}\mtx{r}_k = \mtx{B}\mtx{u}_{ff}
\end{equation*}

To solve for $\mtx{u}_{ff}$, we need to take the inverse of the nonsquare matrix
$\mtx{B}$. This isn't possible, but we can find the pseudoinverse given some
constraints on the state tracking error and control effort. To find the optimal
solution for these sorts of trade-offs, one can define a cost function and
attempt to minimize it. To do this, we'll first solve the expression for
$\mtx{0}$.

\begin{equation*}
  \mtx{0} = \mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)
\end{equation*}

This expression will be the state tracking cost we use in our cost function.

Our cost function will use an $H_2$ norm with $\mtx{Q}$ as the state cost matrix
with dimensionality $states \times states$ and $\mtx{R}$ as the control input
cost matrix with dimensionality $inputs \times inputs$.

\begin{equation*}
  \mtx{J} = (\mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k))^T \mtx{Q}
    (\mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)) +
    \mtx{u}_{ff}^T\mtx{R}\mtx{u}_{ff}
\end{equation*}

\begin{remark}
  $\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k$ will only return a nonzero vector if the
  reference isn't following the system dynamics. If it is, the feedback
  controller already compensates for it. This feedforward compensates for any
  unmodeled dynamics reflected in how the reference is changing (or not
  changing). In the case of a constant reference, the feedforward opposes any
  system dynamics that would change the state over time.
\end{remark}

\begin{align*}
  \mtx{J} &= (\mtx{B}\mtx{u}_{ff} - \mtx{r}_{k+1} + \mtx{A}\mtx{r}_k)^T \mtx{Q}
    (\mtx{B}\mtx{u}_{ff} - \mtx{r}_{k+1} + \mtx{A}\mtx{r}_k) +
    \mtx{u}_{ff}^T\mtx{R}\mtx{u}_{ff} \\
  \mtx{J} &= ((\mtx{B}\mtx{u}_{ff})^T - \mtx{r}_{k+1}^T + (\mtx{A}\mtx{r}_k)^T)
    \mtx{Q}(\mtx{B}\mtx{u}_{ff} - \mtx{r}_{k+1} + \mtx{A}\mtx{r}_k) +
    \mtx{u}_{ff}^T\mtx{R}\mtx{u}_{ff} \\
  \mtx{J} &= (\mtx{u}_{ff}^T\mtx{B}^T - \mtx{r}_{k+1}^T + \mtx{r}_k^T\mtx{A}^T)
    \mtx{Q}(\mtx{B}\mtx{u}_{ff} - \mtx{r}_{k+1} + \mtx{A}\mtx{r}_k) +
    \mtx{u}_{ff}^T\mtx{R}\mtx{u}_{ff} \\
  \mtx{J} &= (\mtx{u}_{ff}^T\mtx{B}^T\mtx{Q} - \mtx{r}_{k+1}^T\mtx{Q} +
    \mtx{r}_k^T\mtx{A}^T\mtx{Q})(\mtx{B}\mtx{u}_{ff} - \mtx{r}_{k+1} +
    \mtx{A}\mtx{r}_k) + \mtx{u}_{ff}^T\mtx{R}\mtx{u}_{ff} \\
  \begin{split}
    \mtx{J} &= \mtx{u}_{ff}^T\mtx{B}^T\mtx{Q}\mtx{B}\mtx{u}_{ff} -
      \mtx{r}_{k+1}^T\mtx{Q}\mtx{B}\mtx{u}_{ff} +
      \mtx{r}_k^T\mtx{A}^T\mtx{Q}\mtx{B}\mtx{u}_{ff} + \\
      &(\mtx{u}_{ff}^T\mtx{B}^T\mtx{Q} -
       \mtx{r}_{k+1}^T\mtx{Q} + \mtx{r}_k^T\mtx{A}^T\mtx{Q})
      (-\mtx{r}_{k+1} + \mtx{A}\mtx{r}_k) + \mtx{u}_{ff}^T\mtx{R}\mtx{u}_{ff}
  \end{split}
\end{align*}

Given theorem \ref{thm:partial}

\begin{theorem}
  $\frac{\partial}{\partial\mtx{A}}\left(\mtx{A}^T\mtx{B}\mtx{A}\right) =
    2\mtx{A}^T\mtx{B}$
  \label{thm:partial}
\end{theorem}

find the minimum by taking the partial derivative of $\mtx{J}$ with respect to
$\mtx{u}_{ff}$ and setting that to $\mtx{0}$.

\begin{align*}
  \frac{\partial\mtx{J}}{\partial\mtx{u}_{ff}} &=
    2\mtx{u}_{ff}^T\mtx{B}^T\mtx{Q}\mtx{B} - 2\mtx{r}_{k+1}^T\mtx{Q}\mtx{B} +
    2\mtx{r}_k^T\mtx{A}^T\mtx{Q}\mtx{B} + 2\mtx{u}_{ff}^T\mtx{R} \\
  \mtx{0} &= 2\mtx{u}_{ff}^T\mtx{B}^T\mtx{Q}\mtx{B} -
    2\mtx{r}_{k+1}^T\mtx{Q}\mtx{B} + 2\mtx{r}_k^T\mtx{A}^T\mtx{Q}\mtx{B} +
    2\mtx{u}_{ff}^T\mtx{R} \\
  \mtx{0} &= \mtx{u}_{ff}^T\mtx{B}^T\mtx{Q}\mtx{B} -
    \mtx{r}_{k+1}^T\mtx{Q}\mtx{B} + \mtx{r}_k^T\mtx{A}^T\mtx{Q}\mtx{B} +
    \mtx{u}_{ff}^T\mtx{R} \\
  \mtx{u}_{ff}^T\mtx{B}^T\mtx{Q}\mtx{B} + \mtx{u}_{ff}^T\mtx{R} &=
    \mtx{r}_{k+1}^T\mtx{Q}\mtx{B} - \mtx{r}_k^T\mtx{A}^T\mtx{Q}\mtx{B} \\
  \mtx{B}^T\mtx{Q}^T\mtx{B}\mtx{u}_{ff} + \mtx{R}^T\mtx{u}_{ff} &=
    \mtx{B}^T\mtx{Q}^T\mtx{r}_{k+1} - \mtx{B}^T\mtx{Q}^T\mtx{A}\mtx{r}_k \\
  (\mtx{B}^T\mtx{Q}^T\mtx{B} + \mtx{R}^T)\mtx{u}_{ff} &=
    \mtx{B}^T\mtx{Q}^T(\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k) \\
  \mtx{u}_{ff} &= (\mtx{B}^T\mtx{Q}^T\mtx{B} +
    \mtx{R}^T)^{-1}\mtx{B}^T\mtx{Q}^T(\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)
\end{align*}

\begin{theorem}[Two-state feedforward]
  \begin{align}
    \mtx{u}_{ff} &= \mtx{K}_{ff} (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k) \\
    \text{where $\mtx{K}_{ff}$ is given by} \nonumber \\
    \mtx{K}_{ff} &=
      (\mtx{B}^T\mtx{Q}^T\mtx{B} + \mtx{R}^T)^{-1}\mtx{B}^T\mtx{Q}^T
  \end{align}
\end{theorem}

If control effort is considered inexpensive, $\mtx{R} \ll \mtx{Q}$ and
$\mtx{u}_{ff}$ approaches the following.

\begin{theorem}[Two-state feedforward with inexpensive control effort]
  \begin{align}
    \mtx{u}_{ff} &= \mtx{K}_{ff} (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k) \\
    \text{where $\mtx{K}_{ff}$ is given by} \nonumber \\
    \mtx{K}_{ff} &= (\mtx{B}^T\mtx{Q}^T\mtx{B})^{-1}\mtx{B}^T\mtx{Q}^T
  \end{align}
\end{theorem}

\begin{remark}
  If the cost matrix $\mtx{Q}$ isn't included in the cost function (that is,
  $\mtx{Q}$ is set to the identity matrix), $\mtx{K}_{ff}$ becomes the
  Moore-Penrose pseudoinverse of $\mtx{B}$ given by
  $\mtx{B}^\dagger = (\mtx{B}^T\mtx{B})^{-1}\mtx{B}^T$.
\end{remark}
