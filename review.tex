\section{What is control theory?}

How can we prove an autonomous car will behave safely and meet certain
performance specifications in the presence of uncertainty? Control theory is a
pragmatic application of algebra and geometry that is used to analyze and
predict the behavior of \glspl{system} such as these, make them respond how we
want them to, and make them \glslink{robustness}{robust} to \glspl{disturbance}
and uncertainty. \\

But what sets control theory apart from, say, applied math? While control theory
does have some beautiful math behind it, controls engineering is an engineering
discipline like any other filled with trade-offs. The solutions control theory
gives should always be sanity checked and informed by our performance
specifications. We don't need to be perfect, just good enough to meet our
specifications.

\section{Nomenclature}

Most resources for advanced engineering topics assume a level of knowledge well
above that which is necessary. See the glossary for a list of words and phrases
commonly used in control theory, their origins, and their meaning.

\section{Control system basics}

\subsection{What is gain?}

Gain is a proportional value that shows the relationship between the magnitude
of the input to the magnitude of the output signal at steady state. Many
\glspl{system} contain a method by which the gain can be altered, providing more
or less "power" to the \gls{system}. However, increasing gain or decreasing gain
beyond a particular safety zone can cause the \gls{system} to become unstable.

\subsection{Block diagrams}

When designing or analyzing a control system, it is useful to model it
graphically. Block diagrams are used for this purpose. They can be manipulated
and simplified systematically \cite{bib:block_diagrams}. Figure
\ref{fig:feedback_loop} is an example of one with a feedback configuration.

\begin{figure}[H]
  \centering

  \begin{tikzpicture}[auto, >=latex']
    % Place the blocks
    \node [name=input] {$X(s)$};
    \node [sum, right=of input] (sum) {};
    \node [block, right=of sum] (P1) {$P_1$};
    \node [right=of P1] (output) {$Y(s)$};
    \node [block, below=of P1] (P2) {$P_2$};

    % Connect the nodes
    \draw [arrow] (input) -- node[pos=0.85] {$+$} (sum);
    \draw [arrow] (sum) -- node {} (P1);
    \draw [arrow] (P1) -- node[name=y] {} (output);
    \draw [arrow] (y) |- (P2);
    \draw [arrow] (P2) -| node[pos=0.97, right] {$\mp$} (sum);
  \end{tikzpicture}

  \caption{Feedback block diagram}
  \label{fig:feedback_loop}
\end{figure}

\subsection{Why feedback control?}

Let's say we are controlling a DC brushed motor. With just a mathematical
\glslink{model}{mathematical model} and knowledge of all current \glspl{state}
of the \gls{system} (i.e., angular velocity), we can predict all future
\glspl{state} given the future voltage \glspl{input}. Why then do we need
feedback control? If the system is \glslink{disturbance}{disturbed} in any way
that isn't modeled by our equations, like a load was applied to the armature, or
voltage sag in the rest of the circuit caused the commanded voltage to not match
the actual applied voltage, the angular velocity of the motor will deviate from
the \gls{model} over time. \\

To combat this, we can take measurements of the system and the environment to
detect this deviation and account for it. For example, we could measure the
current position and estimate an angular velocity from it. We can then give the
motor corrective commands as well as steer our \gls{model} back to reality. This
feedback allows us to account for and be \glslink{robustness}{robust} in the
face of uncertainty.

\section{Review of PID controller mathematics}

\subsection{PID basics and theory}

Negative feedback loops drive the difference between \gls{reference} and
\gls{output} to zero. \\

\textbf{Proportional} gain compensates for current \gls{error}. \\
\textbf{Integral} gain compensates for past error (i.e.,
\gls{steady-state error}). \\
\textbf{Derivative} gain compensates for future error by slowing controller down
  if error decreases over time.

\begin{figure}[H]
  \centering

  \begin{tikzpicture}[auto, >=latex']
    \fontsize{9pt}{10pt}

    % Place the blocks
    \node [name=input] {$r(t)$};
    \node [sum, right=0.5cm of input] (errorsum) {};
    \node [coordinate, right=0.75cm of errorsum] (branch) {};
    \node [block, right=0.5cm of branch] (I) { $K_i \int_0^t e(\tau) d\tau$ };
    \node [block, above=0.5cm of I] (P) { $K_p e(t)$ };
    \node [block, below=0.5cm of I] (D) { $K_d \frac{de(t)}{dt}$ };
    \node [sum, right=0.5cm of I] (ctrlsum) {};
    \node [block, right=0.75cm of ctrlsum] (plant) {Plant};
    \node [right=0.75cm of plant] (output) {};
    \node [coordinate, below=0.5cm of D] (measurements) {};

    % Connect the nodes
    \draw [arrow] (input) -- node[pos=0.9] {$+$} (errorsum);
    \draw [-] (errorsum) -- node {$e(t)$} (branch);
    \draw [arrow] (branch) |- (P);
    \draw [arrow] (branch) -- (I);
    \draw [arrow] (branch) |- (D);
    \draw [arrow] (P) -| node[pos=0.95, left] {$+$} (ctrlsum);
    \draw [arrow] (I) -- node[pos=0.9, below] {$+$} (ctrlsum);
    \draw [arrow] (D) -| node[pos=0.95, right] {$+$} (ctrlsum);
    \draw [arrow] (ctrlsum) -- node {$u(t)$} (plant);
    \draw [arrow] (plant) -- node [name=y] {$y(t)$} (output);
    \draw [-] (y) |- (measurements);
    \draw [arrow] (measurements) -| node[pos=0.99, right] {$-$} (errorsum);
  \end{tikzpicture}

  \caption{PID controller diagram}
  \label{fig:pid_ctrl_diag}
\end{figure}

\begin{center}
  \renewcommand{\arraystretch}{1.3}
  \begin{tabulary}{\linewidth}{LLLL}
    $r(t)$ & \gls{reference} input & $u(t)$ & control input \\
    $e(t)$ & error & $y(t)$ & \gls{output} \\
  \end{tabulary}
\end{center}

\begin{table}
  \caption{Plant versus controller}
  \renewcommand{\arraystretch}{1.3}
  \centering
  \begin{tabular}{|l|ll|}
    \hline
    \rowcolor{lightblue}
    & \textbf{Plant} & \textbf{Controller} \\
    \hline
    Input & $u(t)$ & $r(t)$, $y(t)$ \\
    Output & $y(t)$ & $u(t)$ \\
    \hline
  \end{tabular}
  \label{tab:plant_v_controller}
\end{table}

\subsection{Types of PID controllers}

PID controller inputs of different orders of derivatives, such as position and
velocity, affect the \gls{system} response differently. The position PID
controller is defined as

\begin{equation}
  u(t) = K_p e(t) + K_i \int_0^t e(\tau) d\tau + K_d \frac{de}{dt}
\end{equation}

If a velocity is passed instead, which is a change in position, the equation
becomes

\begin{align}
  \frac{du}{dt} &= K_p \frac{de}{dt} + K_i \int_0^t \frac{de}{d\tau} d\tau +
    K_d \frac{d^2e}{dt^2} \nonumber \\
  \frac{du}{dt} &= K_p \frac{de}{dt} + K_i e(t) + K_d \frac{d^2e}{dt^2}
    \label{eq:pid_vel}
\end{align}

This shows that $K_i$ and $K_p$ from the position controller act as proportional
and derivative terms respectively in the velocity controller. $K_i$ from the
position controller has no equivalent in the velocity controller. If we were to
implement one, it would use a double integral. However, it would be of limited
use since the $K_i$ term in equation (\ref{eq:pid_vel}) also eliminates
steady-state error for step changes in \gls{reference}. Relabelling the
coefficients to match the position PID controller gives

\begin{equation}
  \frac{du}{dt} = K_p \int_0^t e(\tau) d\tau + K_d e(t)
\end{equation}

Read \url{https://en.wikipedia.org/wiki/PID_controller} for more information.

\subsection{Limitations of PID control}

PID's heuristic method of tuning is fine when there is no knowledge of the
\gls{system}. However, controllers with much better response can be developed if
a \glslink{model}{dynamical model} of the \gls{system} is known.
