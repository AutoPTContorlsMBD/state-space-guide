\chapterimage{pid-controllers.jpg}{Treeline by Crown/Merril bus stop at UCSC}

\chapter{PID controllers}

\section{PID basics and theory}
\index{PID control}

Negative feedback loops drive the difference between the \gls{reference} and
\gls{output} to zero. PID control has three gains for this.

\textbf{Proportional} gain compensates for current \gls{error}. \\
\textbf{Integral} gain compensates for past error (i.e.,
\gls{steady-state error}). \\
\textbf{Derivative} gain compensates for future error by slowing controller down
if error decreases over time.

These gains act more when farther away from the \gls{reference} and less as the
error decreases. They are like ``software springs" in a sense that pull the
system's \gls{output} toward the \gls{reference}. Figure \ref{fig:pid_ctrl_diag}
shows a block diagram for a system controlled by a PID controller.

\begin{bookfigure}
  \begin{tikzpicture}[auto, >=latex']
    \fontsize{9pt}{10pt}

    % Place the blocks
    \node [name=input] {$r(t)$};
    \node [sum, right=0.5cm of input] (errorsum) {};
    \node [coordinate, right=0.75cm of errorsum] (branch) {};
    \node [block, right=0.5cm of branch] (I) { $K_i \int_0^t e(\tau) \,d\tau$ };
    \node [block, above=0.5cm of I] (P) { $K_p e(t)$ };
    \node [block, below=0.5cm of I] (D) { $K_d \frac{de(t)}{dt}$ };
    \node [sum, right=0.5cm of I] (ctrlsum) {};
    \node [block, right=0.75cm of ctrlsum] (plant) {Plant};
    \node [right=0.75cm of plant] (output) {};
    \node [coordinate, below=0.5cm of D] (measurements) {};

    % Connect the nodes
    \draw [arrow] (input) -- node[pos=0.9] {$+$} (errorsum);
    \draw [-] (errorsum) -- node {$e(t)$} (branch);
    \draw [arrow] (branch) |- (P);
    \draw [arrow] (branch) -- (I);
    \draw [arrow] (branch) |- (D);
    \draw [arrow] (P) -| node[pos=0.95, left] {$+$} (ctrlsum);
    \draw [arrow] (I) -- node[pos=0.9, below] {$+$} (ctrlsum);
    \draw [arrow] (D) -| node[pos=0.95, right] {$+$} (ctrlsum);
    \draw [arrow] (ctrlsum) -- node {$u(t)$} (plant);
    \draw [arrow] (plant) -- node [name=y] {$y(t)$} (output);
    \draw [-] (y) |- (measurements);
    \draw [arrow] (measurements) -| node[pos=0.99, right] {$-$} (errorsum);
  \end{tikzpicture}

  \caption{PID controller diagram}
  \label{fig:pid_ctrl_diag}

  \begin{figurekey}
    \begin{tabulary}{\linewidth}{LLLL}
      $r(t)$ & \gls{reference} input & $u(t)$ & control input \\
      $e(t)$ & error & $y(t)$ & \gls{output} \\
    \end{tabulary}
  \end{figurekey}
\end{bookfigure}

A system driven by a PID controller generally has three types of responses:
underdamped, overdamped, and critically damped. These are shown in figure
\ref{fig:pid_responses}.

\begin{svg}{build/code/pid_responses}
  \caption{Types of PID controller responses}
  \label{fig:pid_responses}
\end{svg}

For the step responses in figure \ref{fig:pid_responses}, \textit{rise time} is
the time the system takes to initially reach the \gls{reference} after applying
the step input. \textit{Settling time} is the time the system takes to settle at
the \gls{reference} after the step input is applied. An underdamped response
oscillates around the \gls{reference} before settling. An overdamped response is
slow to rise and does not overshoot the \gls{reference}. A critically damped
response has the fastest rise time without overshooting the \gls{reference}.

\section{Types of PID controllers}

PID controller inputs of different orders of derivatives, such as position and
velocity, affect the \gls{system} response differently. Below is the standard
form for a position PID controller.

\begin{definition}[Position PID controller]
  \begin{equation}
    u(t) = K_p e(t) + K_i \int_0^t e(\tau) \,d\tau + K_d \frac{de}{dt}
    \label{eq:pos_pid}
  \end{equation}

  where $e(t)$ is the position error at the current time $t$, $\tau$ is the
  integration variable, $K_p$ is the proportional gain, $K_i$ is the integral
  gain, and $K_d$ is the derivative gain.
\end{definition}

The integral integrates from time $0$ to the current time $t$. We use $\tau$ for
the integration because we need a variable to take on multiple values throughout
the integral, but we can't use $t$ because we already defined that as the
current time.

If the position controller formulation is measuring and controlling velocity
instead, the error $e(t)$ becomes $\frac{de}{dt}$. Substituting this into
equation (\ref{eq:pos_pid}) yields

\begin{align}
  u(t) &= K_p \frac{de}{dt} + K_i \int_0^t \frac{de}{d\tau} \,d\tau +
    K_d \frac{d^2e}{dt^2} \nonumber \\
  u(t) &= K_p \frac{de}{dt} + K_i e(t) + K_d \frac{d^2e}{dt^2}
    \label{eq:u_de_dt}
\end{align}

So the velocity $\frac{de}{dt}$ is integrated by the integral term. By the
fundamental theorem of calculus, the derivative and integral cancel because they
are inverse operations. This produces just the error $e(t)$, so the $K_i$ term
has the effect of proportional control. Furthermore, the $K_p$ term in equation
(\ref{eq:u_de_dt}) behaves like a derivative term for velocity PID control due
to the $\frac{de}{dt}$. Letting $e_v = \frac{de}{dt}$, this means the velocity
controller is analogous to theorem \ref{thm:vel_pid}.

Note this isn't strictly true because the fundamental theorem of calculus
requires that $e(t)$ is continuous, but when we actually implement the
controller, $e(t)$ is discrete. Therefore, the result here is only correct up to
the accuracy of the iterative integration method used. We'll discuss
approximations like these in section \ref{sec:discretization_methods} and how
they affect controller behavior.

\begin{theorem}[Velocity PID controller]
  \label{thm:vel_pid}

  \begin{equation}
    u(t) = K_p e_v(t) + K_i \int_0^t e_v(\tau) \,d\tau
  \end{equation}

  where $e_v(t)$ is the velocity error at the current time $t$, $\tau$ is the
  integration variable, $K_p$ is now the derivative gain, and $K_i$ is now the
  proportional gain.
\end{theorem}

Integral control for the velocity is analogous to the throttle pedal on a car.
One must hold the throttle pedal (the control input) at a nonzero value to keep
the car traveling at the reference velocity.

Read \url{https://en.wikipedia.org/wiki/PID_controller} for more information on
PID control theory.

\section{PID control in terms of general control theory}

PID control defines \textit{setpoint} as the desired position and
\textit{process value} as the measured position. Control theory has more general
terms for these: \gls{reference} and \gls{output} respectively.

The derivative term is commonly used to ``slow down" the system if it's already
heading toward the \gls{reference}. We will explore what $K_p$ and $K_d$ are
really doing for a two-state system (position and velocity) and why $K_d$ acts
that way.

First, we will rearrange the equation for a PD controller.

\begin{equation*}
  u_k = K_p e_k + K_d \frac{e_k - e_{k-1}}{dt}
\end{equation*}

where $u_k$ is the control input at timestep $k$ and $e_k$ is the error at
timestep $k$. $e_k$ is defined as $e_k = r_k - x_k$ where $r_k$ is the reference
and $x_k$ is the current state at timestep $k$.

\begin{align*}
  u_k &= K_p (r_k - x_k) + K_d \frac{(r_k - x_k) - (r_{k-1} - x_{k-1})}{dt} \\
  u_k &= K_p (r_k - x_k) + K_d \frac{r_k - x_k - r_{k-1} + x_{k-1}}{dt} \\
  u_k &= K_p (r_k - x_k) + K_d \frac{r_k - r_{k-1} - x_k + x_{k-1}}{dt} \\
  u_k &= K_p (r_k - x_k) + K_d \frac{(r_k - r_{k-1}) - (x_k - x_{k-1})}{dt} \\
  u_k &= K_p (r_k - x_k) + K_d \left(\frac{r_k - r_{k-1}}{dt} -
    \frac{x_k - x_{k-1}}{dt}\right)
\end{align*}

Notice how $\frac{r_k - r_{k-1}}{dt}$ is the velocity of the reference. By the
same reasoning, $\frac{x_k - x_{k-1}}{dt}$ is the system's velocity at a given
timestep. That means the $K_d$ term of the PD controller is driving the
estimated velocity to the reference velocity. If the reference is constant, that
means the $K_d$ term is trying to drive the velocity of the system to zero.

However, $K_p$ and $K_d$ are controlling the same actuator, and their effects
conflict with each other; $K_p$ is trying to make the system move while $K_d$ is
trying to stop it. If $K_p$ is larger than $K_d$, one is in effect slowing down
the response of the controller during transients with the hope of decreasing
overshoot and settling time. If one makes $K_d$ much larger than $K_p$, $K_d$
overpowers $K_p$ to bring the system to a stop. However, when the velocity is
low enough, $K_p$ is stronger and starts accelerating the system again. This
oscillatory behavior in the velocity repeats as the system moves toward the
reference.

\section{Limitations of PID control}

PID's heuristic method of tuning is a reasonable choice when there is no a
priori knowledge of the \gls{system} dynamics. However, controllers with much
better response can be developed if a \glslink{model}{dynamical model} of the
\gls{system} is known. Furthermore, PID only applies to single-input,
single-output (SISO) systems and can drive up to two \glspl{state} to
\glspl{reference} by using both the proportional and integral terms. We'll
revisit this in subsection \ref{subsec:flywheel-pid-control}.
